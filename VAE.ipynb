{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE\n",
    "\n",
    "\n",
    "Useful ressources :\n",
    "https://www.youtube.com/watch?v=qJeaCHQ1k2w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as r\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import cv2\n",
    "import absl.logging\n",
    "import logging\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.WARNING)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(gpus, \"Physical GPUs,\", logical_gpus, \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "CONSTANTS\n",
    "'''\n",
    "\n",
    "# CONSTANTES\n",
    "DATASET_FOLDER = 'datasets/vae' # Dataset folder with images\n",
    "MODEL_FOLDER = 'models/vae' # Folder to save and load models\n",
    "bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "chosen_dataset = input('Choose the dataset (mnist, celeba, default : mnist) : ') or 'mnist'\n",
    "if chosen_dataset == 'mnist' :\n",
    "    DATASET_FOLDER = 'datasets/mnist'\n",
    "    DATASET_SPLIT = (0.80, 0.15, 0.05) # Split between train, val and test\n",
    "    IMAGE_SIZE = (28, 28) # Heigth, Width\n",
    "    MODEL_EPOCHS = 1000 # Number of epoch\n",
    "    MODEL_BATCH_SIZE = 64 # batch size\n",
    "    MODEL_LEARNING_RATE = 1e-4\n",
    "    KL_FACTOR = 1e-5\n",
    "    MODEL_PATIENCE = 10\n",
    "\n",
    "elif chosen_dataset == 'celeba' :\n",
    "    DATASET_FOLDER = 'datasets/celeba'\n",
    "    DATASET_SPLIT = (0.75,0.20,0.05) # Split between train, val and test\n",
    "    IMAGE_SIZE = (576, 1024) # Heigth, Width\n",
    "    MODEL_EPOCHS = 1000 # Number of epoch\n",
    "    MODEL_BATCH_SIZE = 4 # batch size\n",
    "    MODEL_LEARNING_RATE = 1e-4\n",
    "    KL_FACTOR = 1e-5\n",
    "    MODEL_PATIENCE = 10\n",
    "\n",
    "else :\n",
    "    raise ValueError(f'Unknown dataset : {chosen_dataset}')\n",
    "\n",
    "\n",
    "# Select generator\n",
    "def select_generator():\n",
    "    selected_input = input('Choose the generator (train, val, test, default : train) : ')\n",
    "    if selected_input == '' :\n",
    "        return train_generator\n",
    "    elif selected_input == 'train' :\n",
    "        return train_generator\n",
    "    elif selected_input == 'val' :\n",
    "        return val_generator\n",
    "    elif selected_input == 'test' :\n",
    "        return test_generator\n",
    "    else :\n",
    "        raise ValueError('Unknown subset (train, val, test)')\n",
    "\n",
    "# Select Model learning rate\n",
    "def select_learning_rate():\n",
    "    global MODEL_LEARNING_RATE\n",
    "    learning_rate = input(f'Choose the learning rate (default : {MODEL_LEARNING_RATE}) : ')\n",
    "    if learning_rate != '' :\n",
    "        MODEL_LEARNING_RATE = float(learning_rate)\n",
    "    return MODEL_LEARNING_RATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for MNIST dataset\n",
    "class Generator_MNIST(Sequence):\n",
    "    mnist = None\n",
    "\n",
    "    def __init__(self, ensemble):\n",
    "        super(Generator_MNIST, self).__init__()\n",
    "        self.ensemble = ensemble\n",
    "        if Generator_MNIST.mnist is None:\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "            # Combine all data to split it according to DATASET_SPLIT\n",
    "            x_data = np.concatenate([x_train, x_test])\n",
    "            y_data = np.concatenate([y_train, y_test])\n",
    "\n",
    "            num_samples = len(x_data)\n",
    "            num_train = int(num_samples * DATASET_SPLIT[0])\n",
    "            num_val = int(num_samples * DATASET_SPLIT[1])\n",
    "\n",
    "            # Assign training, validation, and test sets\n",
    "            self.train_images, self.train_labels = x_data[:num_train], y_data[:num_train]\n",
    "            self.val_images, self.val_labels = x_data[num_train:num_train+num_val], y_data[num_train:num_train+num_val]\n",
    "            self.test_images, self.test_labels = x_data[num_train+num_val:], y_data[num_train+num_val:]\n",
    "\n",
    "            # Store in mnist attribute\n",
    "            Generator_MNIST.mnist = {\n",
    "                'train': (self.train_images, self.train_labels),\n",
    "                'val': (self.val_images, self.val_labels),\n",
    "                'test': (self.test_images, self.test_labels)\n",
    "            }\n",
    "        \n",
    "        # Assign the dataset based on the ensemble parameter\n",
    "        self.images, self.labels = Generator_MNIST.mnist[ensemble]\n",
    "        self.indices = np.arange(len(self.images))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / MODEL_BATCH_SIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * MODEL_BATCH_SIZE\n",
    "        end = min((index + 1) * MODEL_BATCH_SIZE, len(self.indices))\n",
    "        batch_x = (self.images[self.indices[start:end]] / 255.0) #* 2 - 1\n",
    "        #batch_y = self.labels[self.indices[start:end]] \n",
    "        return batch_x, batch_x  # x and y are the same image\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indices for the next epoch\n",
    "        np.random.shuffle(self.indices)\n",
    "    \n",
    "# Generator for CelebA dataset\n",
    "class Generator_CelebA(Sequence):\n",
    "    celeba = None\n",
    "    \n",
    "    def __init__(self, ensemble):\n",
    "        super(Generator_CelebA, self).__init__()\n",
    "        self.ensemble = ensemble\n",
    "        if Generator_CelebA.celeba is None:\n",
    "            self.image_filenames = [f for f in os.listdir(DATASET_FOLDER) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "            self.indices = np.arange(len(self.image_filenames))\n",
    "            \n",
    "            num_samples = len(self.image_filenames)\n",
    "            num_train = int(num_samples * DATASET_SPLIT[0])\n",
    "            num_val = int(num_samples * DATASET_SPLIT[1])\n",
    "            num_test = int(num_samples * DATASET_SPLIT[2])\n",
    "            \n",
    "            # Assign training, validation, and test sets\n",
    "            self.train_images = self.image_filenames[:num_train]\n",
    "            self.val_images = self.image_filenames[num_train:num_train+num_val]\n",
    "            self.test_images = self.image_filenames[num_train+num_val:]\n",
    "            \n",
    "            # Store in celeba attribute\n",
    "            Generator_CelebA.celeba = {\n",
    "                'train': self.train_images,\n",
    "                'val': self.val_images,\n",
    "                'test': self.test_images\n",
    "            }\n",
    "        \n",
    "        # Assign the dataset based on the ensemble parameter\n",
    "        self.image_filenames = Generator_CelebA.celeba[ensemble]\n",
    "        self.indices = np.arange(len(self.image_filenames))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / MODEL_BATCH_SIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * MODEL_BATCH_SIZE\n",
    "        end = min((index + 1) * MODEL_BATCH_SIZE, len(self.image_filenames))\n",
    "        batch_filenames = self.image_filenames[start:end]\n",
    "        batch_images = []\n",
    "        for filename in batch_filenames:\n",
    "            image_path = os.path.join(self.directory_path, filename)\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize(IMAGE_SIZE)\n",
    "                img = np.array(img, dtype=np.float32)\n",
    "                img = (img / 255.0) #* 2 - 1\n",
    "            batch_images.append(img)\n",
    "        \n",
    "        batch_images = np.array(batch_images)\n",
    "        return batch_images, batch_images\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)  # Shuffle indices to mix up batches\n",
    "\n",
    "if chosen_dataset == 'mnist' :\n",
    "    train_generator = Generator_MNIST('train')\n",
    "    val_generator = Generator_MNIST('val')\n",
    "    test_generator = Generator_MNIST('test')\n",
    "elif chosen_dataset == 'celeba' :\n",
    "    train_generator = Generator_CelebA('train')\n",
    "    val_generator = Generator_CelebA('val')\n",
    "    test_generator = Generator_CelebA('test')\n",
    "else :\n",
    "    raise ValueError(f'Unknown dataset : {chosen_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = select_generator()\n",
    "idx = r.randint(0, len(generator) - 1)\n",
    "batch = generator[idx][0]\n",
    "print(f'Batch shape : {batch.shape}')\n",
    "print(f'Batch type : {type(batch)}')\n",
    "idx = r.randint(0, len(batch) - 1)\n",
    "image = batch[idx]\n",
    "# Plot X \n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Encodeur MNIST\n",
    "def encoder_MNIST(): \n",
    "    inputs = layers.Input(shape=IMAGE_SIZE + (1,))\n",
    "    x = layers.Conv2D(32, 3, activation='leaky_relu', strides=1, padding='same')(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2D(128, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2D(128, 3, activation='leaky_relu', strides=1, padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='leaky_relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    z_mean = layers.Dense(5, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(5, name='z_log_var')(x)\n",
    "    z = layers.Lambda(sampling, output_shape=(2,), name='z')([z_mean, z_log_var])\n",
    "    return models.Model(inputs, [z_mean, z_log_var,z], name='encoder'), z_mean, z_log_var\n",
    "\n",
    "# Encodeur CelebA\n",
    "def encoder_celebA():\n",
    "    inputs = layers.Input(shape=IMAGE_SIZE + (3,))\n",
    "    x = layers.Conv2D(32, 3, activation='leaky_relu', strides=2, padding='same')(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2D(128, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2D(256, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='leaky_relu')(x)\n",
    "    z_mean = layers.Dense(50, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(50, name='z_log_var')(x)\n",
    "    z = layers.Lambda(sampling, output_shape=(50,), name='z')([z_mean, z_log_var])\n",
    "    return models.Model(inputs, [z_mean, z_log_var, z], name='encoder_celeba'), z_mean, z_log_var\n",
    "\n",
    "# Décodeur MNIST\n",
    "def decoder_MNIST():\n",
    "    latent_inputs = layers.Input(shape=(5,))\n",
    "    x = layers.Dense(7*7*64, activation='leaky_relu')(latent_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Reshape((7, 7, 64))(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation='leaky_relu', strides=1, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='leaky_relu', strides=1, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    # On supprime la dimension en trop a la fin\n",
    "    output = layers.Reshape((28, 28))(x)\n",
    "    return models.Model(latent_inputs, output, name='decoder')\n",
    "\n",
    "# Décodeur CelebA\n",
    "def decoder_celebA():\n",
    "    latent_inputs = layers.Input(shape=(50,))\n",
    "    x = layers.Dense(8*16*256, activation='leaky_relu')(latent_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Reshape((8, 16, 256))(x)\n",
    "    x = layers.Conv2DTranspose(128, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation='leaky_relu', strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(3, 3, activation='sigmoid', padding='same')(x)\n",
    "    return models.Model(latent_inputs, x, name='decoder_celeba')\n",
    "\n",
    "# VAE model\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Définir les métriques\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")    \n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "    \n",
    "        # Calcule la perte\n",
    "        reconstruction_loss, kl_loss, total_loss = vae_loss(inputs, reconstructed, z_mean, z_log_var)\n",
    "        \n",
    "        # Mise à jour des trackers de métrique\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x = data[0] # x and y is the batch of images\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstructed = self.decoder(z, training=True)\n",
    "            # Calcule la perte\n",
    "            reconstruction_loss, kl_loss, total_loss = vae_loss(x, reconstructed, z_mean, z_log_var)\n",
    "            # Backward pass\n",
    "            gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "            # Mise à jour des trackers de métrique\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
    "\n",
    "def vae_loss(y, vae_output, z_mean, z_log_var):\n",
    "    reconstruction_loss = mse(y, vae_output)\n",
    "    \n",
    "    # Divergence KL\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "    kl_loss = tf.reduce_mean(kl_loss) * KL_FACTOR\n",
    "    return reconstruction_loss, kl_loss, reconstruction_loss + kl_loss\n",
    "\n",
    "# For Keras API\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return tf.constant(0.0)\n",
    "\n",
    "\n",
    "if chosen_dataset == 'mnist' :\n",
    "    encoder, z_mean, z_log_var = encoder_MNIST()\n",
    "    decoder = decoder_MNIST()\n",
    "elif chosen_dataset == 'celeba' :\n",
    "    encoder, z_mean, z_log_var = encoder_celebA()\n",
    "    decoder = decoder_celebA()\n",
    "\n",
    "model = VAE(encoder, decoder)\n",
    "model.compile(optimizer='adam', loss=zero_loss)\n",
    "model.build((None, *IMAGE_SIZE, 1 if chosen_dataset == 'mnist' else 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_dtype=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_total_loss', patience=MODEL_PATIENCE, mode='min', restore_best_weights=True, verbose=2)\n",
    "\n",
    "# Entraînement du VAE\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=MODEL_EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des courbes d'apprentissage, avec les différentes pertes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['reconstruction_loss'], label='reconstruction_loss')\n",
    "plt.plot(history.history['kl_loss'], label='kl_loss')\n",
    "plt.legend()\n",
    "plt.title('Training loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['val_total_loss'], label='val_total_loss')\n",
    "plt.plot(history.history['val_reconstruction_loss'], label='val_reconstruction_loss')\n",
    "plt.plot(history.history['val_kl_loss'], label='val_kl_loss')\n",
    "plt.legend()\n",
    "plt.title('Validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = select_generator()\n",
    "idx = r.randint(0, len(generator) - 1)\n",
    "batch = generator[idx][0]\n",
    "idx = r.randint(0, len(batch) - 1)\n",
    "sample = batch[np.newaxis, idx]\n",
    "\n",
    "# On encode l'image\n",
    "z_mean, z_log_var, z = encoder.predict(sample, verbose=0)\n",
    "print(\"z_mean: \", z_mean)\n",
    "print(\"z_log_var: \", z_log_var)\n",
    "print(\"z: \", z)\n",
    "\n",
    "# On décode l'image\n",
    "x_reconstructed = decoder.predict(z, verbose=0)\n",
    "\n",
    "# Affichage de l'image originale et de l'image reconstruite\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Image originale\")\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Image reconstruite\")\n",
    "plt.imshow(x_reconstructed[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moyenne des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cluster = input('Choose a cluster number : ')\n",
    "n_samples = 9\n",
    "z_samples = np.random.normal(\n",
    "    mean_z_mean[input_cluster],\n",
    "    np.sqrt(np.exp(mean_z_log_var[input_cluster])),\n",
    "    (n_samples, 2)\n",
    ")\n",
    "x_samples = decoder.predict(z_samples)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(f'Génération du cluster {input_cluster}')\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_samples[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
