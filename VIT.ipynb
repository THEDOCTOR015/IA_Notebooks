{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIT\n",
    "\n",
    "MS COCO 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import clear_output\n",
    "from pycocotools.coco import COCO\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(gpu)\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes et variables globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ANNOTDIR = 'annotations_trainval2014'\n",
    "DATADIR = 'train2014'\n",
    "INSTANCEFILE = '{}/annotations/instances_{}.json'.format(ANNOTDIR, DATADIR)\n",
    "\n",
    "# Hyper-paramètres\n",
    "RATIO_TRAIN = 0.8\n",
    "RATIO_VAL = 0.15\n",
    "RATIO_TEST = 0.05\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PATIENCE = 3\n",
    "COCO_INSTANCES = COCO(INSTANCEFILE)\n",
    "NUM_TOTAL_CLASSES = 91 # 80 classes + 10 classes omises + 1 car base 1\n",
    "PATCHES_SIZE = 12\n",
    "INPUT_SHAPE = (224, 224, 3) # Taille des images\n",
    "GLOBAL_THRESHOLD = 0.25\n",
    "\n",
    "# Configuration de l'augmentation\n",
    "DATA_GEN = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Vérifications\n",
    "assert RATIO_TRAIN + RATIO_VAL + RATIO_TEST == 1 # Vérification de la somme des ratios\n",
    "\n",
    "num_classes = len(COCO_INSTANCES.getCatIds())\n",
    "print(f'Nombre de classes dans le dataset COCO: {num_classes}')\n",
    "\n",
    "# Métriques\n",
    "#F1_SCORE = tf.keras.metrics.F1Score()\n",
    "\n",
    "# Couches custom\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID'\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        num_patches = (images.shape[1] // self.patch_size) * (images.shape[2] // self.patch_size)\n",
    "        patches = tf.reshape(patches, [batch_size, num_patches, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"patch_size\": self.patch_size}\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"num_patches\": self.num_patches, \"projection_dim\": self.projection.units}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Sequence):\n",
    "    def _getsplit(self, ensemble):\n",
    "        if ensemble == 'train':\n",
    "            start = 0\n",
    "            stop = int(RATIO_TRAIN * len(self.imgIds))\n",
    "        elif ensemble == 'val':\n",
    "            start = int(RATIO_TRAIN * len(self.imgIds))\n",
    "            stop = int((RATIO_TRAIN + RATIO_VAL) * len(self.imgIds))\n",
    "        elif ensemble == 'test':\n",
    "            start = int((RATIO_TRAIN + RATIO_VAL) * len(self.imgIds))\n",
    "            stop = len(self.imgIds)\n",
    "        return start, stop\n",
    "\n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        # Créer une liste de tous les IDs d'images\n",
    "        self.imgIds = COCO_INSTANCES.getImgIds()\n",
    "        start, stop = self._getsplit(ensemble)\n",
    "        self.ids = self.imgIds[start:stop]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids) / BATCH_SIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.ids[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for id in batch_ids:\n",
    "            # Charger l'image\n",
    "            file_name = COCO_INSTANCES.imgs[id]['file_name']\n",
    "            image = Image.open(f'{DATADIR}/{file_name}')\n",
    "            image = image.resize((224, 224))\n",
    "            image = image.convert('RGB')\n",
    "            image = np.array(image)\n",
    "            if self.ensemble == 'train':\n",
    "                image = DATA_GEN.random_transform(image)\n",
    "            image = np.array(image)\n",
    "            batch_images.append(image)\n",
    "            # Charger les classes\n",
    "            annIds = COCO_INSTANCES.getAnnIds(imgIds=id)\n",
    "            anns = COCO_INSTANCES.loadAnns(annIds)\n",
    "            labels = [0.0 for _ in range(NUM_TOTAL_CLASSES)]\n",
    "            for ann in anns:\n",
    "                labels[ann['category_id']] = 1.0\n",
    "            batch_labels.append(labels)\n",
    "\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_images = np.array(batch_images)\n",
    "\n",
    "        return (batch_images, batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.ids = np.random.permutation(self.ids)\n",
    "\n",
    "train_generator = DatasetGenerator('train')\n",
    "val_generator = DatasetGenerator('val')\n",
    "test_generator = DatasetGenerator('test')\n",
    "\n",
    "print(f'Taille du dataset d\\'entrainement: {len(train_generator)} batches, {len(train_generator.ids)} items')\n",
    "print(f'Taille du dataset de validation: {len(val_generator)} batches, {len(val_generator.ids)} items')\n",
    "print(f'Taille du dataset de test: {len(test_generator)} batches, {len(test_generator.ids)} items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test de performance du générateur de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "generator = train_generator # Temps négligeable\n",
    "r_index = np.random.randint(len(generator)) # Temps négligeable\n",
    "generator.__getitem__(r_index-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test unitaire du générateur de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "# Récupérer un batch d'images et de légendes\n",
    "r_index = np.random.randint(len(generator)-1)\n",
    "images, labels = generator.__getitem__(r_index)\n",
    "# Extraire une image et ses classes\n",
    "r_index = np.random.randint(len(images))\n",
    "image = images[r_index]\n",
    "label = labels[r_index]\n",
    "label_ids= [str(i) for i in np.where(label == 1)[0]]\n",
    "label_str = ', '.join([ COCO_INSTANCES.cats[int(i)]['name'] for i in label_ids])\n",
    "# Afficher une image et ses classes\n",
    "plt.imshow(image)\n",
    "plt.title(f'Classes: {label_str}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test du patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "# Récupérer un batch d'images et de légendes\n",
    "r_index = np.random.randint(len(generator)-1)\n",
    "images, labels = generator.__getitem__(r_index)\n",
    "# Extraire une image et ses classes\n",
    "r_index = np.random.randint(len(images))\n",
    "image = images[r_index]\n",
    "patches = Patches(patch_size=PATCHES_SIZE)(np.expand_dims(image, axis=0))\n",
    "print(f\"Patch size: {PATCHES_SIZE} X {PATCHES_SIZE}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = np.array(patch).reshape(PATCHES_SIZE, PATCHES_SIZE, 3)\n",
    "    plt.imshow(patch_img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CUSTOM MODELS ###\n",
    "\n",
    "def VIT_v1():\n",
    "    '''\n",
    "    inputs :\n",
    "    - image : (224, 224, 3)\n",
    "    outputs :\n",
    "    - class : (91)\n",
    "    results :\n",
    "    \n",
    "    '''\n",
    "    def transformer_block(x, num_heads, projection_dim, ff_dim, dropout):\n",
    "        # Normalisation et Multi-Head Attention\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention, x])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "        # Normalisation et Feed-Forward\n",
    "        x3 = layers.Dense(units=ff_dim, activation='gelu')(x3)\n",
    "        x3 = layers.Dropout(dropout)(x3)\n",
    "        x3 = layers.Dense(units=projection_dim, activation='gelu')(x3)\n",
    "        x3 = layers.Dropout(dropout)(x3)\n",
    "        final = layers.Add()([x3, x2])\n",
    "        return final\n",
    "\n",
    "    # Création du modèle\n",
    "    dropout_start = 0.20\n",
    "    dropout_end = 0.55\n",
    "    dropout_middle = 0.05\n",
    "    projection_dim = 128+32\n",
    "    ff_dim_multiplier = 6\n",
    "    num_heads = 4\n",
    "    num_blocks = 48\n",
    "\n",
    "    image_input = layers.Input(shape=INPUT_SHAPE)\n",
    "    x = layers.BatchNormalization()(image_input)\n",
    "    x = layers.Dropout(dropout_start)(x)\n",
    "    x = Patches(PATCHES_SIZE)(x)\n",
    "    num_patches = (INPUT_SHAPE[0] // PATCHES_SIZE) * ( INPUT_SHAPE[1] // PATCHES_SIZE)\n",
    "    size_patch = PATCHES_SIZE * PATCHES_SIZE * INPUT_SHAPE[-1]\n",
    "    print(f'Nombre de patches: {num_patches}')\n",
    "    print(f'Taille d\\'un patch: {size_patch}')\n",
    "    x = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim)(x)\n",
    "\n",
    "    # Transformer\n",
    "    for _ in range(num_blocks):\n",
    "        x = transformer_block(x, num_heads=num_heads, projection_dim=projection_dim, ff_dim=projection_dim*ff_dim_multiplier, dropout=dropout_middle)\n",
    "    \n",
    "    # Classification\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    #x = layers.GlobalAveragePooling1D()(x)\n",
    "    #x = layers.Lambda(lambda x: x[ :, -1, :])(x)\n",
    "    #x = layers.Dense(128, activation='leaky_relu')(x)\n",
    "    x = layers.Dropout(dropout_end)(x)\n",
    "    output = layers.Dense(NUM_TOTAL_CLASSES, activation='sigmoid')(x) # sigmoid pour multi-label classification\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output, name='VIT_v1')\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "model = VIT_v1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=f'{model.name}.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=PATIENCE, \n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[early_stopping, tensorboard_callback],\n",
    "                    verbose=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{model.name}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement d'un modèle pré-existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('VIT_v1_2210.keras', custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbe ROC\n",
    "Permet d'obtenir le meilleure threshold pour chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = train_generator\n",
    "# Récupérer les labels et les prédictions pour l'ensemble de test\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(generator)):\n",
    "    images, labels = generator[i]\n",
    "    predictions = model.predict(images,verbose = 0)\n",
    "    y_true.append(labels)\n",
    "    y_pred.append(predictions)\n",
    "    clear_output()\n",
    "    print(f'Batch {i+1}/{len(generator)}')\n",
    "\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "# Calculer les courbes ROC et les AUC pour chaque classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "thresholds = dict()\n",
    "\n",
    "for i in range(NUM_TOTAL_CLASSES):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Trouver le meilleur seuil pour chaque classe\n",
    "best_thresholds = dict()\n",
    "for i in range(NUM_TOTAL_CLASSES):\n",
    "    gmeans = np.sqrt(tpr[i] * (1-fpr[i]))\n",
    "    ix = np.argmax(gmeans)\n",
    "    best_thresholds[i] = thresholds[i][ix]\n",
    "\n",
    "# On clear les prints\n",
    "clear_output()\n",
    "\n",
    "# Tracer les courbes ROC pour quelques classes\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(NUM_TOTAL_CLASSES):\n",
    "    if i in COCO_INSTANCES.cats :\n",
    "        plt.plot(fpr[i], tpr[i], label=f'{COCO_INSTANCES.cats[i][\"name\"]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC')\n",
    "#plt.legend(loc='lower right') # Trop de classes pour afficher la légende\n",
    "plt.show()\n",
    "\n",
    "print(\"Meilleurs seuils pour chaque classe:\")\n",
    "print(best_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test unitaire du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_global_threshold = True\n",
    "\n",
    "generator = train_generator\n",
    "# Récupérer un batch d'images et de labels\n",
    "r_index = np.random.randint(len(generator)-1)\n",
    "images, labels = generator.__getitem__(r_index)\n",
    "    \n",
    "# Choisir une image au hasard dans le batch\n",
    "batch_size = images.shape[0]\n",
    "r_index = np.random.randint(batch_size-1)\n",
    "image = images[r_index]\n",
    "label = labels[r_index]\n",
    "\n",
    "label_str = ', '.join([ COCO_INSTANCES.cats[int(i)]['name'] for i in np.where(label == 1)[0]])\n",
    "    \n",
    "image_expanded = np.expand_dims(image, axis=0)  # Ajouter une dimension pour correspondre au batch_size\n",
    "predictions = model.predict(image_expanded)\n",
    "    \n",
    "# Extraire les prédictions pour l'image sélectionnée\n",
    "predicted_label = predictions[0]\n",
    "# Tri des classes prédites en fonction de l'assurance du modèle\n",
    "predicted_classes = np.argsort(predicted_label)[::-1]\n",
    "if use_global_threshold:\n",
    "    predicted_classes = [i for i in predicted_classes if predicted_label[i] > GLOBAL_THRESHOLD]\n",
    "else:\n",
    "    predicted_classes = [i for i in predicted_classes if predicted_label[i] > best_thresholds[i]]\n",
    "predicted_str = ', '.join([COCO_INSTANCES.cats[int(i)]['name'] for i in predicted_classes])\n",
    "\n",
    "# Afficher l'image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Classes prédites: {predicted_str} \\nClasses réelles: {label_str}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
