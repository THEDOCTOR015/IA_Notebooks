{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIT\n",
    "\n",
    "MS COCO 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from pycocotools.coco import COCO\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(gpus)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes et variables globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ANNOTDIR = 'annotations_trainval2014'\n",
    "DATADIR = 'train2014'\n",
    "INSTANCEFILE = '{}/annotations/instances_{}.json'.format(ANNOTDIR, DATADIR)\n",
    "\n",
    "# Hyper-paramètres\n",
    "RATIO_TRAIN = 0.8\n",
    "RATIO_VAL = 0.15\n",
    "RATIO_TEST = 0.05\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PATIENCE = 3\n",
    "COCO_INSTANCES = COCO(INSTANCEFILE)\n",
    "NUM_TOTAL_CLASSES = 91 # 80 classes + 10 classes omises + 1 car base 1\n",
    "PATCHES_SIZE = 16\n",
    "INPUT_SHAPE = (224, 224, 3) # Taille des images\n",
    "\n",
    "# Vérifications\n",
    "assert RATIO_TRAIN + RATIO_VAL + RATIO_TEST == 1 # Vérification de la somme des ratios\n",
    "\n",
    "num_classes = len(COCO_INSTANCES.getCatIds())\n",
    "print(f'Nombre de classes dans le dataset COCO: {num_classes}')\n",
    "\n",
    "# Métriques\n",
    "#F1_SCORE = tf.keras.metrics.F1Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Sequence):\n",
    "    def _getsplit(self, ensemble):\n",
    "        if ensemble == 'train':\n",
    "            start = 0\n",
    "            stop = int(RATIO_TRAIN * len(self.imgIds))\n",
    "        elif ensemble == 'val':\n",
    "            start = int(RATIO_TRAIN * len(self.imgIds))\n",
    "            stop = int((RATIO_TRAIN + RATIO_VAL) * len(self.imgIds))\n",
    "        elif ensemble == 'test':\n",
    "            start = int((RATIO_TRAIN + RATIO_VAL) * len(self.imgIds))\n",
    "            stop = len(self.imgIds)\n",
    "        return start, stop\n",
    "\n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        # Créer une liste de tous les IDs d'images\n",
    "        self.imgIds = COCO_INSTANCES.getImgIds()\n",
    "        start, stop = self._getsplit(ensemble)\n",
    "        self.ids = self.imgIds[start:stop]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids) / BATCH_SIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.ids[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for id in batch_ids:\n",
    "            # Charger l'image\n",
    "            file_name = COCO_INSTANCES.imgs[id]['file_name']\n",
    "            image = Image.open(f'{DATADIR}/{file_name}')\n",
    "            image = image.resize((224, 224))\n",
    "            image = image.convert('RGB')\n",
    "            image = np.array(image)\n",
    "            batch_images.append(image)\n",
    "            # Charger les classes\n",
    "            annIds = COCO_INSTANCES.getAnnIds(imgIds=id)\n",
    "            anns = COCO_INSTANCES.loadAnns(annIds)\n",
    "            labels = [0.0 for _ in range(NUM_TOTAL_CLASSES)]\n",
    "            for ann in anns:\n",
    "                labels[ann['category_id']] = 1.0\n",
    "            batch_labels.append(labels)\n",
    "\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        batch_images = np.array(batch_images)\n",
    "\n",
    "        return (batch_images, batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.ids = np.random.permutation(self.ids)\n",
    "\n",
    "train_generator = DatasetGenerator('train')\n",
    "val_generator = DatasetGenerator('val')\n",
    "test_generator = DatasetGenerator('test')\n",
    "\n",
    "print(f'Taille du dataset d\\'entrainement: {len(train_generator)} batches, {len(train_generator.ids)} items')\n",
    "print(f'Taille du dataset de validation: {len(val_generator)} batches, {len(val_generator.ids)} items')\n",
    "print(f'Taille du dataset de test: {len(test_generator)} batches, {len(test_generator.ids)} items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de performance du générateur de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "generator = train_generator # Temps négligeable\n",
    "r_index = np.random.randint(len(generator)) # Temps négligeable\n",
    "generator.__getitem__(r_index-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test unitaire du générateur de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "# Récupérer un batch d'images et de légendes\n",
    "r_index = np.random.randint(len(generator)-1)\n",
    "images, labels = generator.__getitem__(r_index)\n",
    "# Extraire une image et ses classes\n",
    "r_index = np.random.randint(len(images))\n",
    "image = images[r_index]\n",
    "label = labels[r_index]\n",
    "label_ids= [str(i) for i in np.where(label == 1)[0]]\n",
    "label_str = ', '.join([ COCO_INSTANCES.cats[int(i)]['name'] for i in label_ids])\n",
    "# Afficher une image et ses classes\n",
    "plt.imshow(image)\n",
    "plt.title(f'Classes: {label_str}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### CUSTOM LAYERS ###\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID'\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        num_patches = (images.shape[1] // self.patch_size) * (images.shape[2] // self.patch_size)\n",
    "        patches = tf.reshape(patches, [batch_size, num_patches, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_layer = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        projection = self.projection_layer(patch)\n",
    "        position_embedding = self.position_embedding_layer(positions)\n",
    "        position_embedding = tf.expand_dims(position_embedding, axis=0)\n",
    "        encoded = projection + position_embedding\n",
    "        return encoded\n",
    "\n",
    "### CUSTOM MODELS ###\n",
    "\n",
    "def VIT_v1():\n",
    "    '''\n",
    "    inputs :\n",
    "    - image : (224, 224, 3)\n",
    "    outputs :\n",
    "    - class : (91)\n",
    "    '''\n",
    "    def transformer_block(x, num_heads, projection_dim, ff_dim, dropout):\n",
    "        # Normalisation et Multi-Head Attention\n",
    "        start = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=dropout\n",
    "        )(start, start)\n",
    "        x = x + start\n",
    "        res1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Normalisation et Feed-Forward\n",
    "        x = layers.Dense(units=ff_dim, activation='gelu')(res1)\n",
    "        x = layers.Dense(units=projection_dim, activation='gelu')(x)    \n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        res2 = x + res1\n",
    "        return res2\n",
    "\n",
    "    # Création du modèle\n",
    "    dropout = 0.0\n",
    "    projection_dim = 128\n",
    "    ff_dim_multiplier = 4\n",
    "    num_heads = 8\n",
    "\n",
    "    image_input = layers.Input(shape=INPUT_SHAPE)\n",
    "    x = layers.Rescaling(1./255)(image_input)\n",
    "    x = Patches(PATCHES_SIZE)(x)\n",
    "    num_patches = (INPUT_SHAPE[0] // PATCHES_SIZE) * ( INPUT_SHAPE[1] // PATCHES_SIZE)\n",
    "    size_patch = PATCHES_SIZE * PATCHES_SIZE * INPUT_SHAPE[-1]\n",
    "    print(f'Nombre de patches: {num_patches}')\n",
    "    print(f'Taille d\\'un patch: {size_patch}')\n",
    "    x = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim)(x)\n",
    "\n",
    "    # Transformer\n",
    "    for _ in range(20):\n",
    "        x = transformer_block(x, num_heads=num_heads, projection_dim=projection_dim, ff_dim=projection_dim*ff_dim_multiplier, dropout=dropout)\n",
    "    \n",
    "    # Classification\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    #x = layers.Lambda(lambda x: x[ :, -1, :])(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    output = layers.Dense(NUM_TOTAL_CLASSES, activation='sigmoid')(x) # sigmoid pour multi-label classification\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output, name='VIT_v1')\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = VIT_v1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=f'{model.name}.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=PATIENCE, \n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{model.name}.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test unitaire du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "# Récupérer un batch d'images et de labels\n",
    "r_index = np.random.randint(len(generator)-1)\n",
    "images, labels = generator.__getitem__(r_index)\n",
    "    \n",
    "# Choisir une image au hasard dans le batch\n",
    "batch_size = images.shape[0]\n",
    "r_index = np.random.randint(batch_size-1)\n",
    "image = images[r_index]\n",
    "label = labels[r_index]\n",
    "    \n",
    "image_expanded = np.expand_dims(image, axis=0)  # Ajouter une dimension pour correspondre au batch_size\n",
    "predictions = model.predict(image_expanded)\n",
    "    \n",
    "# Extraire les prédictions pour l'image sélectionnée\n",
    "predicted_label = predictions[0]\n",
    "    \n",
    "# Si c'est du multi-label classification avec sigmoid, on peut utiliser un seuil pour les prédictions\n",
    "threshold = 0.3\n",
    "predicted_classes = (predicted_label > threshold).astype(int)\n",
    "predicted_classes = np.where(predicted_classes == 1)[0]\n",
    "predicted_str = ', '.join([ COCO_INSTANCES.cats[int(i)]['name'] for i in predicted_classes])\n",
    "\n",
    "\n",
    "# Afficher l'image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Classes prédites: {predicted_str}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
