{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion\n",
    "Dataset : MSCOCO 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random as r\n",
    "from tqdm import tqdm # progress bar\n",
    "import time\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs detected: {len(gpus)}\")\n",
    "        print(f\"GPUs: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ANNOTDIR = 'annotations_trainval2014'\n",
    "DATADIR = 'train2014'\n",
    "INSTANCEFILE = '{}/annotations/instances_{}.json'.format(ANNOTDIR, DATADIR)\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "STEPS = 1000 # Nombre d'étapes de diffusion\n",
    "BETA_1 = 1e-4\n",
    "BETA_T = 1e-2\n",
    "PATH_DATASETS = ['stable-diffusion-face-dataset/512/man','stable-diffusion-face-dataset/512/woman']\n",
    "TRAIN_SPLIT = 0.8\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.05\n",
    "EPOCHS = 1000 # L'early stopping est utilisé\n",
    "PATIENCE = 2\n",
    "COCO_INSTANCES = COCO(INSTANCEFILE)\n",
    "model = None\n",
    "\n",
    "# Configuration de l'augmentation\n",
    "DATA_GEN = ImageDataGenerator(\n",
    "    rotation_range=1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "BASE_GEN = ImageDataGenerator()\n",
    "\n",
    "class LinearNoiceScheduler:\n",
    "    def __init__(self):\n",
    "        self.betas = np.linspace(BETA_1, BETA_T, STEPS)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.sqrt_alphas = np.sqrt(self.alphas)\n",
    "        self.c_alphas = np.cumprod(self.alphas)\n",
    "        self.sqrt_c_alphas = np.sqrt(self.c_alphas)\n",
    "        self.sqrt_one_minus_c_alphas = np.sqrt(1 - self.c_alphas)\n",
    "    \n",
    "    def add_noise(self, original_images, steps):\n",
    "        original_shape = original_images.shape\n",
    "        noise = np.random.normal(size=original_shape)\n",
    "\n",
    "        sqrt_alpha_cumprod = self.sqrt_c_alphas[steps]\n",
    "        sqrt_one_minus_alpha_cumprod = self.sqrt_one_minus_c_alphas[steps]\n",
    "        sqrt_alpha_cumprod = sqrt_alpha_cumprod[ :, np.newaxis, np.newaxis, np.newaxis]\n",
    "        sqrt_one_minus_alpha_cumprod = sqrt_one_minus_alpha_cumprod[ :, np.newaxis, np.newaxis, np.newaxis]\n",
    "\n",
    "        noisy_image = sqrt_alpha_cumprod*original_images + sqrt_one_minus_alpha_cumprod*noise\n",
    "        return noisy_image\n",
    "\n",
    "    def remove_noise(self, noisy_image, pred_noise, step, stability_factor=True):\n",
    "        # Récupération des paramètres pour l'étape t\n",
    "        alpha_t = self.alphas[step]\n",
    "        sqrt_alpha_t = np.sqrt(alpha_t)\n",
    "        sqrt_one_minus_cum_alpha_t = self.sqrt_one_minus_c_alphas[step]\n",
    "\n",
    "        alpha_factor = ( 1 - alpha_t ) / sqrt_one_minus_cum_alpha_t\n",
    "        \n",
    "        # Calcul de l'image mise à jour x_{t-1}\n",
    "        updated_image = (1 / sqrt_alpha_t) * (noisy_image - (alpha_factor * pred_noise))\n",
    "        \n",
    "        # Ajout du terme de stabilité pour les étapes non finales\n",
    "        if step > 0 and stability_factor:\n",
    "            sigma_t = np.sqrt(self.betas[step])\n",
    "            noise = np.random.normal(size=noisy_image.shape)\n",
    "            updated_image += sigma_t * noise\n",
    "        \n",
    "        return updated_image\n",
    "\n",
    "def inference():\n",
    "    res = []\n",
    "    image = np.random.normal(size=INPUT_SHAPE)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    res.append((STEPS, image))\n",
    "    with tqdm(total=STEPS, desc='Inference', unit='step') as pbar:\n",
    "        for step in range(STEPS-1, -1, -1):\n",
    "            noise_pred = model.predict(image, verbose=0)\n",
    "            image = NoiceScheduler.remove_noise(image, noise_pred, step)\n",
    "            pbar.update()\n",
    "            if step % 100 == 0:\n",
    "                res.append((step, image))\n",
    "    return res\n",
    "\n",
    "def plot_inference():\n",
    "    result = inference()\n",
    "    fig, axes = plt.subplots(1, len(result), figsize=(20, 5))\n",
    "    for i, res in enumerate(result):\n",
    "        step, img = res\n",
    "        img = (img + 1) / 2 # Convertion de -1, 1 à 0, 1\n",
    "        axes[i].imshow(np.clip(img[0], 0, 1))\n",
    "        axes[i].set_title(f'{step}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "NoiceScheduler = LinearNoiceScheduler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data préprosessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Sequence):\n",
    "    def _getsplit(self, ensemble):\n",
    "        if ensemble == 'train':\n",
    "            start = 0\n",
    "            stop = int(TRAIN_SPLIT * len(self.imgIds))\n",
    "        elif ensemble == 'val':\n",
    "            start = int(TRAIN_SPLIT * len(self.imgIds))\n",
    "            stop = int((TRAIN_SPLIT + VALIDATION_SPLIT) * len(self.imgIds))\n",
    "        elif ensemble == 'test':\n",
    "            start = int((TRAIN_SPLIT + VALIDATION_SPLIT) * len(self.imgIds))\n",
    "            stop = len(self.imgIds)\n",
    "        return start, stop\n",
    "\n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        # Créer une liste de tous les IDs d'images\n",
    "        self.imgIds = COCO_INSTANCES.getImgIds()\n",
    "        start, stop = self._getsplit(ensemble)\n",
    "        self.ids = self.imgIds[start:stop]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids) / BATCH_SIZE))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.ids[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for id in batch_ids:\n",
    "            # Charger l'image\n",
    "            file_name = COCO_INSTANCES.imgs[id]['file_name']\n",
    "            image = Image.open(f'{DATADIR}/{file_name}')\n",
    "            image = image.resize((224, 224))\n",
    "            image = image.convert('RGB')\n",
    "            image = img_to_array(image)\n",
    "            image = (image / 255.0) * 2 - 1 # Normalisation entre -1 et 1\n",
    "            if self.ensemble == 'train':\n",
    "                image = DATA_GEN.random_transform(image)\n",
    "            else :\n",
    "                image = BASE_GEN.random_transform(image)\n",
    "            batch_images.append(image)\n",
    "            # Créer le label en rajoutant du bruit\n",
    "            step = np.array([np.random.randint(1, STEPS)])\n",
    "            label = NoiceScheduler.add_noise(image, step)\n",
    "            label = label[0]\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        batch_labels = np.array(batch_labels, dtype='float64')\n",
    "        batch_images = np.array(batch_images, dtype='float64')\n",
    "\n",
    "        return (batch_images, batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.ensemble == 'train':\n",
    "            np.random.shuffle(self.ids)\n",
    "\n",
    "train_generator = DatasetGenerator('train')\n",
    "val_generator = DatasetGenerator('val')\n",
    "test_generator = DatasetGenerator('test')\n",
    "\n",
    "print(f'Taille du dataset d\\'entrainement: {len(train_generator)} batches, {len(train_generator.ids)} items')\n",
    "print(f'Taille du dataset de validation: {len(val_generator)} batches, {len(val_generator.ids)} items')\n",
    "print(f'Taille du dataset de test: {len(test_generator)} batches, {len(test_generator.ids)} items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Sélectionner un batch aléatoire\n",
    "batch_index = np.random.randint(0, len(train_generator))\n",
    "images, labels = train_generator.__getitem__(batch_index)\n",
    "print(f'Images shape: {images.shape}')\n",
    "print(f'Labels shape: {labels.shape}')\n",
    "\n",
    "# Sélectionner une image aléatoire dans le batch\n",
    "image_index = np.random.randint(0, len(images))\n",
    "image = images[image_index] # On prend le premier élément de l'axe des batchs\n",
    "image = (image + 1) / 2 # On remet les valeurs de pixels entre 0 et 1\n",
    "label = labels[image_index] # On prend le premier élément de l'axe des batchs\n",
    "label = (label + 1) / 2 # On remet les valeurs de pixels entre 0 et 1\n",
    "print(f'Image shape: {image.shape}')\n",
    "print(f'Label shape: {label.shape}')\n",
    "\n",
    "# Afficher l'image et son label\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(np.clip(image, 0, 1))\n",
    "axes[0].set_title('Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(np.clip(label, 0, 1))\n",
    "axes[1].set_title('Label (Noisy Image)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian noice tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_images = 10\n",
    "\n",
    "# Sélectionner nb_images aléatoires du dataset\n",
    "selected_images = data[np.random.choice(len(data), nb_images, replace=False)] / 255.0\n",
    "noise = np.random.normal(size=selected_images.shape[1:])\n",
    "\n",
    "# Initialiser les listes pour stocker les moyennes et les écarts types\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "step_jump = 10\n",
    "\n",
    "# Calculer la moyenne et l'écart type à chaque étape\n",
    "for step in range(0, STEPS, step_jump):\n",
    "    noisy_images = NoiceScheduler.add_noise(selected_images, step)\n",
    "    means.append(np.mean(noisy_images))\n",
    "    stds.append(np.std(noisy_images))\n",
    "\n",
    "# Plot des résultats\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(0, STEPS, step_jump), means, label='Mean')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Mean')\n",
    "plt.title('Mean of Noisy Images')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(0, STEPS, step_jump), stds, label='Standard Deviation')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.title('Standard Deviation of Noisy Images')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# On prend quelques images aléatoires\n",
    "idx = r.randint(1, len(selected_images)-1)\n",
    "test_images = selected_images[:idx]\n",
    "\n",
    "# Show noise\n",
    "plt.figure(figsize=(6, 6))\n",
    "noise_img = np.clip(noise, 0, 1)\n",
    "plt.imshow(noise_img)\n",
    "plt.title('Noise')\n",
    "plt.axis('off')\n",
    "# Show noise distribution\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(noise.flatten(), bins=150)\n",
    "plt.title('Noise Distribution')\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of cumprod_alphas\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(NoiceScheduler.c_alphas)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Cumprod alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'images bruitées à afficher\n",
    "bruitage = 14\n",
    "\n",
    "test_image = data[0]\n",
    "test_image = test_image / 255.0\n",
    "jump = STEPS // bruitage\n",
    "fig, axes = plt.subplots(1, bruitage+1, figsize=(20, 4))\n",
    "for slot in range(bruitage+1):\n",
    "    step = min((slot+1) * jump, STEPS-1)\n",
    "    step = np.array([step])\n",
    "    c_alpha = NoiceScheduler.c_alphas[step]\n",
    "    noisy_images = NoiceScheduler.add_noise(test_image, step)\n",
    "    noisy_image_plt = np.clip(noisy_images, 0, 1)\n",
    "    axes[slot].imshow(noisy_image_plt[0])\n",
    "    axes[slot].axis('off')\n",
    "    axes[slot].set_title(f'{int(step)} - {float(c_alpha):.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    x = layers.Conv2D(num_filters, (3, 3), padding=\"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    x = layers.Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    x = conv_block(input_tensor, num_filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(input_tensor, skip_features, num_filters):\n",
    "    x = layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input_tensor)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    d5 = layers.Concatenate()([d4, inputs])\n",
    "    outputs = layers.Conv2D(3, (1, 1))(d5)  # output is a 3-channel image (RGB)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name='Diffusion_UNet')\n",
    "    return model\n",
    "\n",
    "# Construire le modèle\n",
    "model = build_unet(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file=model.name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "@tf.function\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Training function\n",
    "@tf.function\n",
    "def train_step(model, labels, noises, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(noises, training=True)\n",
    "        predictions = tf.cast(predictions, tf.float64)\n",
    "        loss = loss_fn(noises, predictions) # y_true = noises, y_pred = predictions\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "epochs_losses = []\n",
    "val_epochs_losses = []\n",
    "min_loss = np.inf\n",
    "counter = 0\n",
    "model_save_name = f\"{model.name}_{datetime.datetime.now().strftime('%Y%m%d%H%M')}.keras\"\n",
    "for epoch in range(EPOCHS):\n",
    "    # Entrainement du modèle\n",
    "    with tqdm(total=len(train_generator), desc=f'Epoch {epoch+1}/{EPOCHS}', unit='batch') as pbar:\n",
    "        epoch_losses = []\n",
    "        for step in range(len(train_generator)) :\n",
    "            # Récupérer les images et les bruits\n",
    "            images, noises = train_generator.__getitem__(step)\n",
    "            # Training step\n",
    "            loss = train_step(model, images, noises, optimizer)\n",
    "            # Métriques\n",
    "            epoch_losses.append(loss.numpy())\n",
    "            epoch_loss = np.mean(epoch_losses)\n",
    "            pbar.set_postfix(Loss=f\"{epoch_loss:.6f}\")\n",
    "            pbar.update()\n",
    "    train_generator.on_epoch_end()\n",
    "    epochs_losses.append(np.mean(epoch_losses))\n",
    "    # Validation\n",
    "    with tqdm(total=len(val_generator), desc=f'Validation {epoch+1}/{EPOCHS}', unit='batch') as pbar:\n",
    "        val_losses = []\n",
    "        for step in range(len(val_generator)):\n",
    "            images, noises = val_generator.__getitem__(step)\n",
    "            predictions = model.predict(noises, verbose=0)\n",
    "            predictions = tf.cast(predictions, tf.float64)\n",
    "            loss = loss_fn(noises, predictions)\n",
    "            val_losses.append(loss.numpy())\n",
    "            pbar.set_postfix(Loss=f\"{np.mean(val_losses):.6f}\")\n",
    "            pbar.update()\n",
    "    val_epochs_losses.append(np.mean(val_losses))\n",
    "    # Early stopping\n",
    "    if val_epochs_losses[-1] >= min_loss and epoch > 0:\n",
    "        counter += 1\n",
    "        if counter >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    else:\n",
    "        counter = 0\n",
    "        min_loss = epochs_losses[-1]\n",
    "        save_model(model, model_save_name)\n",
    "    # Affichage d'un test d'inférence\n",
    "    plot_inference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Diffusion_UNet_202411130839.keras', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "plot_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur un bruit gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.normal(size=INPUT_SHAPE)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "for step in range(STEPS-1, -1, -1):\n",
    "    noise_pred = model.predict(image, verbose=0)\n",
    "    image = NoiceScheduler.remove_noise(image, noise_pred, step)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(np.clip(image[0], 0, 1))\n",
    "    plt.title(f'{step}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    clear_output(wait=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test itératif sur une image bruité (image fourni par le dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_index = np.random.randint(0, len(data), 1)\n",
    "print(r_index)\n",
    "images = data[r_index] / 255.0\n",
    "steps = np.random.randint(0, STEPS, size=len(images))\n",
    "noises = NoiceScheduler.add_noise(images, steps)\n",
    "for i in range(int(steps)-1, -1, -1):\n",
    "    noise_pred = model.predict(noises, verbose=0)\n",
    "    noises = NoiceScheduler.remove_noise(noises, noise_pred, i)\n",
    "    plt.imshow(np.clip(noises[0], 0, 1))\n",
    "    plt.title(f'{i}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur une image bruité sur dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_index = np.random.randint(0, len(data), 1)\n",
    "images = data[r_index] / 255.0\n",
    "chosen_steps = np.random.randint(0, STEPS, size=len(images))\n",
    "noises = NoiceScheduler.add_noise(images, chosen_steps)\n",
    "noise_pred = model.predict(noises, verbose=0)\n",
    "denoised_images = images - (noise_pred * ( 1 - NoiceScheduler.c_alphas[chosen_steps] ))\n",
    "print(f\"Chosen steps: {chosen_steps}\")\n",
    "print(f\"Cumprod alphas: {NoiceScheduler.c_alphas[chosen_steps]}\")\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axes[0].imshow(np.clip(images[0], 0, 1))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(np.clip(noises[0], 0, 1))\n",
    "axes[1].set_title('Noisy')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(np.clip(denoised_images[0], 0, 1))\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].axis('off')\n",
    "axes[3].imshow(np.clip(noise_pred[0], 0, 1))\n",
    "axes[3].set_title('Predicted Noise')\n",
    "axes[3].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur une image du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_index = np.random.randint(0, len(data), 1)\n",
    "images = np.zeros((1, 512, 512, 3))\n",
    "chosen_steps = np.random.randint(0, STEPS, size=len(images))\n",
    "noises = NoiceScheduler.add_noise(images, chosen_steps)\n",
    "noise_pred = model.predict(noises, verbose=0)\n",
    "denoised_images = images - (noise_pred * ( 1 - NoiceScheduler.c_alphas[chosen_steps] ))\n",
    "print(f\"Chosen steps: {chosen_steps}\")\n",
    "print(f\"Cumprod alphas: {NoiceScheduler.c_alphas[chosen_steps]}\")\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axes[0].imshow(np.clip(images[0], 0, 1))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(np.clip(noises[0], 0, 1))\n",
    "axes[1].set_title('Noisy')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(np.clip(denoised_images[0], 0, 1))\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].axis('off')\n",
    "axes[3].imshow(np.clip(noise_pred[0], 0, 1))\n",
    "axes[3].set_title('Predicted Noise')\n",
    "axes[3].axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
