{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd8adca",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2d6e7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53169688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from tensorflow.keras.models import save_model, load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random as r\n",
    "from tqdm import tqdm # progress bar\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs detected: {len(gpus)}\")\n",
    "        print(f\"GPUs: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs detected\")\n",
    "\n",
    "tf.config.optimizer.set_jit(True)  # Active JIT (XLA) globalement\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "r.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684f432",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_lr, min_lr, cycle_length, cycle_mult=1.0):\n",
    "        self.initial_lr = initial_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.cycle_length = cycle_length\n",
    "        self.cycle_mult = cycle_mult\n",
    "        self.current_cycle = 0\n",
    "        self.iteration = 0\n",
    "\n",
    "    def __call__(self, step):\n",
    "        cycle_progress = tf.cast(step % self.cycle_length, tf.float32) / tf.cast(self.cycle_length, tf.float32)\n",
    "        cosine_decay = 0.5 * (1 + tf.cos(math.pi * cycle_progress))\n",
    "        lr = self.min_lr + (self.initial_lr - self.min_lr) * cosine_decay\n",
    "        return lr\n",
    "\n",
    "\n",
    "# Constants\n",
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "BATCH_SIZE = 4*32\n",
    "EPOCHS = 300\n",
    "G_RATIO, D_RATIO = 3, 1 # Ratio de mise à jour du générateur et du discriminateur\n",
    "initial_lr = 2e-4\n",
    "min_lr = 5e-6\n",
    "cycle_length = 2000  # nombre de steps avant de redémarrer\n",
    "\n",
    "gen_lr_schedule = CosineAnnealingScheduler(initial_lr, min_lr, cycle_length)\n",
    "disc_lr_schedule = CosineAnnealingScheduler(initial_lr, min_lr, cycle_length)\n",
    "\n",
    "\n",
    "GENERATOR_OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=gen_lr_schedule, beta_1=0.5)\n",
    "DISCRIMINATOR_OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=disc_lr_schedule, beta_1=0.5)\n",
    "\n",
    "IDS = [ f'datasets/Humans_Face/{element}' for element in os.listdir('datasets/Humans_Face') ]\n",
    "IDS += [ f'datasets/celeba/{element}' for element in os.listdir('datasets/celeba') ]\n",
    "r.shuffle(IDS)\n",
    "PATIENCE = 2\n",
    "\n",
    "def inference():\n",
    "    pass\n",
    "\n",
    "def plot_inference(image=None):\n",
    "    result = inference(for_plot=True, image=image)\n",
    "    fig, axes = plt.subplots(1, len(result), figsize=(20, 5))\n",
    "    for i, res in enumerate(result):\n",
    "        step, img = res\n",
    "        img = (img + 1) / 2 # Convertion de -1, 1 à 0, 1\n",
    "        axes[i].imshow(np.clip(img, 0, 1))\n",
    "        axes[i].set_title(f'{int(step)}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def array_stats(array, plot=False):\n",
    "    print(f'Shape: {array.shape} \\n \\\n",
    "        Mean: {np.mean(array)} \\n \\\n",
    "        Min: {np.min(array)} \\n \\\n",
    "        Max: {np.max(array)} \\n \\\n",
    "        Std: {np.std(array)}')\n",
    "    if plot:\n",
    "        sns.histplot(array.flatten())\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599ad79",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Dataset\n",
    "class DatasetGeneratorFace(Sequence):\n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        # Créer une liste de tous les IDs d'images\n",
    "        self.ids = IDS\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids) / BATCH_SIZE))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.ids[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        for id in batch_ids:\n",
    "            # Charger l'image\n",
    "            image = load_img(id, target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]), color_mode='rgb')\n",
    "            image = img_to_array(image)\n",
    "            image = image / 255.0 # Normalisation entre 0 et 1\n",
    "            batch_images.append(image)\n",
    "        \n",
    "        batch_images = np.array(batch_images)\n",
    "\n",
    "        return (batch_images) # On renvoie l'image d'entrée et la cible (auto-encodeur)\n",
    "\n",
    "TrainGen = DatasetGeneratorFace('train')\n",
    "print(f\"Train: {len(TrainGen)} \\n\")\n",
    "\n",
    "# Visualisation des données\n",
    "def plot_data_gen(gen, n=5):\n",
    "    fig, axes = plt.subplots(1, n, figsize=(20, 5))\n",
    "    for i in range(n):\n",
    "        image = gen[i][0]\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_gen(TrainGen, n=5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96186d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5421e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size=3, strides=1, padding='same', activation='leaky_relu', batch_norm=True, transpose=False, dropout=0.0):\n",
    "    if transpose:\n",
    "        x = layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "    else:\n",
    "        x = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    if dropout > 0.0:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_GeneratorModel():\n",
    "    noise_dims = (64,)\n",
    "    noise_input = layers.Input(shape=(noise_dims))\n",
    "\n",
    "    x = layers.Reshape((4, 4, 4))(noise_input)\n",
    "\n",
    "    x = conv_block(x, 256, transpose=True)\n",
    "    x = conv_block(x, 256, transpose=True)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = conv_block(x, 128, transpose=True)\n",
    "    x = conv_block(x, 128, transpose=True)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = conv_block(x, 64, transpose=True)\n",
    "    x = conv_block(x, 64, transpose=True)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = conv_block(x, 64, transpose=True)\n",
    "\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = conv_block(x, 32, transpose=True)\n",
    "    x = conv_block(x, 32, transpose=True)\n",
    "\n",
    "    x = layers.Conv2D(3, kernel_size=3, padding='same')(x)\n",
    "    x = layers.Activation('sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=noise_input, outputs=x, name=\"Generator\")\n",
    "\n",
    "def build_DiscriminatorModel():\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = conv_block(image_input, 32, dropout=0.05)\n",
    "\n",
    "    x = conv_block(x, 64, strides=2, dropout=0.05)\n",
    "\n",
    "    x = conv_block(x, 128, strides=2, dropout=0.05)\n",
    "\n",
    "    x = conv_block(x, 256, strides=2, dropout=0.05)\n",
    "    \n",
    "    x = conv_block(x, 512, strides=2, dropout=0.05)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=image_input, outputs=x, name=\"Discriminator\")\n",
    "\n",
    "GeneratorModel, DiscriminatorModel = build_GeneratorModel(), build_DiscriminatorModel()\n",
    "NOISE_DIM = list(GeneratorModel.input_shape[1:])\n",
    "print(GeneratorModel.summary())\n",
    "print(DiscriminatorModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e821fa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e532b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # car output= sigmoid\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(real_images, DiscriminatorModel, GeneratorModel, turn):\n",
    "    batch_size = real_images.shape[0]\n",
    "    disc_loss, gen_loss = None, None\n",
    "    # === Génération d'images fausses ===\n",
    "    noise = tf.random.normal([batch_size] + NOISE_DIM)\n",
    "    fake_images = GeneratorModel(noise, training=True)\n",
    "\n",
    "    # === Discriminateur ===\n",
    "    real_labels = tf.ones((batch_size, 1))\n",
    "    fake_labels = tf.zeros((batch_size, 1))\n",
    "    if 'discriminator' in turn :\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            real_output = DiscriminatorModel(real_images, training=True)\n",
    "            fake_output = DiscriminatorModel(fake_images, training=True)\n",
    "\n",
    "            disc_loss_real = loss_fn(real_labels, real_output)\n",
    "            disc_loss_fake = loss_fn(fake_labels, fake_output)\n",
    "            disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "        grads_disc = disc_tape.gradient(disc_loss, DiscriminatorModel.trainable_variables)\n",
    "        DISCRIMINATOR_OPTIMIZER.apply_gradients(zip(grads_disc, DiscriminatorModel.trainable_variables))\n",
    "    # === Générateur ===\n",
    "    if 'generator' in turn:\n",
    "        noise = tf.random.normal([batch_size] + NOISE_DIM)\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            generated_images = GeneratorModel(noise, training=True)\n",
    "            fake_output = DiscriminatorModel(generated_images, training=True)\n",
    "            gen_loss = loss_fn(real_labels, fake_output)  # veut tromper le disc\n",
    "\n",
    "        grads_gen = gen_tape.gradient(gen_loss, GeneratorModel.trainable_variables)\n",
    "        GENERATOR_OPTIMIZER.apply_gradients(zip(grads_gen, GeneratorModel.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "wait = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    # --- Entraînement ---\n",
    "    progress_bar = tqdm(TrainGen, desc=\"Training\", leave=False)\n",
    "    for index, real_images in enumerate(progress_bar):\n",
    "        turn= ['discriminator'] if index % (G_RATIO + D_RATIO) < D_RATIO else ['generator']\n",
    "        if index == 0:\n",
    "            turn = ['discriminator', 'generator']\n",
    "        g_loss, d_loss = train_step(real_images, DiscriminatorModel, GeneratorModel, turn)\n",
    "        current_lr = GENERATOR_OPTIMIZER._decayed_lr(tf.float32).numpy()\n",
    "        if g_loss is not None:\n",
    "            pb_g_loss = g_loss\n",
    "        if d_loss is not None:\n",
    "            pb_d_loss = d_loss\n",
    "        progress_bar.set_postfix({\"g_loss\": f\"{pb_g_loss:.4e}\", \"d_loss\": f\"{pb_d_loss:.4e}\", \"lr\": f\"{current_lr:.3e}\"})\n",
    "\n",
    "        # --- Test ---\n",
    "        if index % 100 == 0:\n",
    "            noise = tf.random.normal([5] + NOISE_DIM)\n",
    "            fake_images = GeneratorModel(noise, training=False)\n",
    "            fig, axes = plt.subplots(1, len(fake_images), figsize=(20, 5))\n",
    "            for i, img in enumerate(fake_images):\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    # --- Sauvegarde du modèle ---\n",
    "    if epoch % 5 == 0:\n",
    "        save_model(GeneratorModel, f\"models/gan/GeneratorModel.h5\")\n",
    "        save_model(DiscriminatorModel, f\"models/gan/DiscriminatorModel.h5\")\n",
    "        print(f\"Models saved at epoch {epoch}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
