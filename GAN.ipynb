{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd8adca",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2d6e7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53169688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from tensorflow.keras.models import save_model, load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random as r\n",
    "from tqdm import tqdm # progress bar\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs detected: {len(gpus)}\")\n",
    "        print(f\"GPUs: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs detected\")\n",
    "\n",
    "tf.config.optimizer.set_jit(True)  # Active JIT (XLA) globalement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684f432",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ANNOTDIR = 'datasets/annotations_trainval2014'\n",
    "DATADIR = 'datasets/train2014'\n",
    "INSTANCEFILE = '{}/annotations/instances_{}.json'.format(ANNOTDIR, DATADIR)\n",
    "\n",
    "\n",
    "# Constants\n",
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "BATCH_SIZE = 32*4\n",
    "EPOCHS = 30\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "IDS = [ f'datasets/Humans_Face/{element}' for element in os.listdir('datasets/Humans_Face') ]\n",
    "IDS += [ f'datasets/celeba/{element}' for element in os.listdir('datasets/celeba') ]\n",
    "r.shuffle(IDS)\n",
    "PATIENCE = 2\n",
    "\n",
    "\n",
    "#PATH_DATASETS = ['stable-diffusion-face-dataset/512/man','stable-diffusion-face-dataset/512/woman']\n",
    "TRAIN_SPLIT = 0.8\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.05\n",
    "\n",
    "# Configuration de l'augmentation\n",
    "DATA_GEN = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "BASE_GEN = ImageDataGenerator()\n",
    "\n",
    "def inference():\n",
    "    pass\n",
    "\n",
    "def plot_inference(image=None):\n",
    "    result = inference(for_plot=True, image=image)\n",
    "    fig, axes = plt.subplots(1, len(result), figsize=(20, 5))\n",
    "    for i, res in enumerate(result):\n",
    "        step, img = res\n",
    "        img = (img + 1) / 2 # Convertion de -1, 1 à 0, 1\n",
    "        axes[i].imshow(np.clip(img, 0, 1))\n",
    "        axes[i].set_title(f'{int(step)}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def array_stats(array, plot=False):\n",
    "    print(f'Shape: {array.shape} \\n \\\n",
    "        Mean: {np.mean(array)} \\n \\\n",
    "        Min: {np.min(array)} \\n \\\n",
    "        Max: {np.max(array)} \\n \\\n",
    "        Std: {np.std(array)}')\n",
    "    if plot:\n",
    "        sns.histplot(array.flatten())\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599ad79",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Dataset\n",
    "class DatasetGeneratorFace(Sequence):\n",
    "    def _getsplit(self, ensemble):\n",
    "        if ensemble == 'train':\n",
    "            start = 0\n",
    "            stop = int(TRAIN_SPLIT * len(IDS))\n",
    "        elif ensemble == 'val':\n",
    "            start = int(TRAIN_SPLIT * len(IDS))\n",
    "            stop = int((TRAIN_SPLIT + VALIDATION_SPLIT) * len(IDS))\n",
    "        elif ensemble == 'test':\n",
    "            start = int((TRAIN_SPLIT + VALIDATION_SPLIT) * len(IDS))\n",
    "            stop = len(IDS)\n",
    "        return start, stop\n",
    "    \n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ensemble = ensemble\n",
    "        \n",
    "        # Créer une liste de tous les IDs d'images\n",
    "        start, stop = self._getsplit(ensemble)\n",
    "        self.ids = IDS[start:stop]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids) / BATCH_SIZE))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.ids[index * BATCH_SIZE : (index + 1) * BATCH_SIZE]\n",
    "        batch_images = []\n",
    "        for id in batch_ids:\n",
    "            # Charger l'image\n",
    "            image = load_img(id, target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]), color_mode='rgb')\n",
    "            image = img_to_array(image)\n",
    "            image = (image / 255.0) * 2 - 1 # Normalisation entre -1 et 1\n",
    "            if self.ensemble == 'train':\n",
    "                image = DATA_GEN.random_transform(image)\n",
    "            else :\n",
    "                image = BASE_GEN.random_transform(image)\n",
    "            batch_images.append(image)\n",
    "        \n",
    "        batch_images = np.array(batch_images, dtype='float64')\n",
    "\n",
    "        return (batch_images, batch_images) # On renvoie l'image d'entrée et la cible (auto-encodeur)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.ensemble == 'train': # Sert à rien de shuffle les données de validation et de test\n",
    "            np.random.shuffle(self.ids)\n",
    "\n",
    "TrainGen = DatasetGeneratorFace('train')\n",
    "ValGen = DatasetGeneratorFace('val')\n",
    "TestGen = DatasetGeneratorFace('test')\n",
    "print(f\"Train: {len(TrainGen)} \\n Val: {len(ValGen)} \\n Test: {len(TestGen)}\")\n",
    "\n",
    "# Visualisation des données\n",
    "def plot_data_gen(gen, n=5):\n",
    "    fig, axes = plt.subplots(1, n, figsize=(20, 5))\n",
    "    for i in range(n):\n",
    "        image = gen[i][0][0]\n",
    "        image = (image + 1) / 2 # Convertion de -1, 1 à 0, 1\n",
    "        axes[i].imshow(np.clip(image, 0, 1))\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_gen(TrainGen, n=5)\n",
    "plot_data_gen(ValGen, n=5)\n",
    "plot_data_gen(TestGen, n=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96186d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5421e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_GeneratorModel():\n",
    "    noise_dim = 100\n",
    "    noise_input = layers.Input(shape=(noise_dim,))\n",
    "\n",
    "    x = layers.Dense(4*4*1024, use_bias=False)(noise_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Reshape((4, 4, 1024))(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(512, kernel_size=5, strides=2, padding='same', use_bias=False)(x)  # 8x8x512\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=5, strides=2, padding='same', use_bias=False)(x)  # 16x16x256\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding='same', use_bias=False)(x)  # 32x32x128\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', use_bias=False, activation='tanh')(x)  # 64x64x3\n",
    "\n",
    "    return Model(inputs=noise_input, outputs=x, name=\"Generator\")\n",
    "\n",
    "def build_DiscriminatorModel():\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = layers.Conv2D(64, kernel_size=5, strides=2, padding='same')(image_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs=image_input, outputs=x, name=\"Discriminator\")\n",
    "\n",
    "GeneratorModel, DiscriminatorModel = build_GeneratorModel(), build_DiscriminatorModel()\n",
    "NOISE_DIM = GeneratorModel.input_shape\n",
    "print(GeneratorModel.summary())\n",
    "print(DiscriminatorModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e821fa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e532b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # car output= sigmoid\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images, Generator, Discriminator, batch_size):\n",
    "    # === Génération d'images fausses ===\n",
    "    noise = tf.random.normal([batch_size, NOISE_DIM])\n",
    "    fake_images = Generator(noise, training=True)\n",
    "\n",
    "    # === Discriminateur ===\n",
    "    real_labels = tf.ones((batch_size, 1))\n",
    "    fake_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        real_output = Discriminator(real_images, training=True)\n",
    "        fake_output = Discriminator(fake_images, training=True)\n",
    "\n",
    "        disc_loss_real = loss_fn(real_labels, real_output)\n",
    "        disc_loss_fake = loss_fn(fake_labels, fake_output)\n",
    "        disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "    grads_disc = disc_tape.gradient(disc_loss, Discriminator.trainable_variables)\n",
    "    OPTIMIZER.apply_gradients(zip(grads_disc, Discriminator.trainable_variables))\n",
    "\n",
    "    # === Générateur ===\n",
    "    noise = tf.random.normal([batch_size, NOISE_DIM])\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = Generator(noise, training=True)\n",
    "        fake_output = Discriminator(generated_images, training=True)\n",
    "        gen_loss = loss_fn(real_labels, fake_output)  # veut tromper le disc\n",
    "\n",
    "    grads_gen = gen_tape.gradient(gen_loss, Generator.trainable_variables)\n",
    "    OPTIMIZER.apply_gradients(zip(grads_gen, Generator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "wait = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    # --- Entraînement ---\n",
    "    progress_bar = tqdm(TrainGen, desc=\"Training\", leave=False)\n",
    "    for real_images in progress_bar:\n",
    "        g_loss, d_loss = train_step(real_images, GeneratorModel, DiscriminatorModel, BATCH_SIZE)\n",
    "        progress_bar.set_postfix({\"g_loss\": f\"{g_loss:.4f}\", \"d_loss\": f\"{d_loss:.4f}\"})\n",
    "\n",
    "    # --- Validation ---\n",
    "    val_g_losses = []\n",
    "    for val_real_images in ValGen:\n",
    "        noise = tf.random.normal([val_real_images.shape[0], NOISE_DIM])\n",
    "        generated_images = GeneratorModel(noise, training=False)\n",
    "        val_fake_output = DiscriminatorModel(generated_images, training=False)\n",
    "        val_loss = loss_fn(tf.ones_like(val_fake_output), val_fake_output)\n",
    "        val_g_losses.append(val_loss)\n",
    "\n",
    "    avg_val_g_loss = tf.reduce_mean(val_g_losses)\n",
    "    print(f\"Validation Generator Loss: {avg_val_g_loss:.4f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if avg_val_g_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_g_loss\n",
    "        wait = 0\n",
    "        # Optionnel : sauvegarde du meilleur modèle\n",
    "        GeneratorModel.save_weights(\"best_generator_weights.h5\")\n",
    "        DiscriminatorModel.save_weights(\"best_discriminator_weights.h5\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch+1} (no improvement in {PATIENCE} epochs).\")\n",
    "            break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
