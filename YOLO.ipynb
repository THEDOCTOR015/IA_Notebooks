{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO\n",
    "**/!\\ This version of YOLO does not include class and multi scale predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import absl.logging\n",
    "import logging\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm # progress bar\n",
    "from datetime import datetime\n",
    "from ipywidgets import Dropdown, Layout, Button, VBox, HBox, Output\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.WARNING)\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(gpus, \"Physical GPUs,\", logical_gpus, \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "'''\n",
    "CONSTANTS\n",
    "'''\n",
    "\n",
    "# CONSTANTES\n",
    "DATASET_FOLDER = 'datasets/yolo' # Dataset folder with annotations and images\n",
    "MODEL_FOLDER = 'models/yolo' # Folder to save and load models\n",
    "DATASET_SPLIT = (0.75,0.20,0.05) # Split between train, val and test\n",
    "LABELS_FOLDER = DATASET_FOLDER + '/labels'\n",
    "IMAGES_FOLDER = DATASET_FOLDER + '/images'\n",
    "IMAGE_SIZE = (576, 1024) # Heigth, Width\n",
    "MODEL_EPOCHS = 1000 # Number of epoch\n",
    "MODEL_CELLULES = (18,32) # Number of cells heigth, width (line,column)\n",
    "MODEL_BATCH_SIZE = 4 # batch size\n",
    "MODEL_LEARNING_RATE = 1e-4\n",
    "MODEL_PATIENCE = 10\n",
    "BOK_FACTOR = 3 # Number of boxes to keep for the BoK\n",
    "\n",
    "MODEL_ANCHOR_BOXES = [(1.0583118277729953, 1.049340222907784), (8.59272329748259, 2.6783446036374645), (18.042821164159008, 10.97661303553199), (2.988349659829224, 6.10604402643905), (2.1024247923276076, 2.270861681701132), (14.716370144570341, 3.3927061962834175), (10.948179662161893, 6.239582909394387), (6.07272101508836, 3.739122200908468), (8.002992148445207, 15.429423262078899), (29.46776909562174, 3.8386150181052767), (3.4639113280451594, 1.7175792011783335), (6.309270699179344, 7.352531098636265), (20.385446192500307, 2.959357080172756), (5.362068949615781, 2.033512908678979), (4.161533434208954, 11.930562829810054), (1.0825721324291453, 2.166483835080819), (3.5172166305716233, 3.310328528940259), (1.987218503609958, 1.2044695947380342)]\n",
    "\n",
    "MODEL_LAMBDA_COORD = 0.9\n",
    "MODEL_LAMBDA_IOU = 0.6\n",
    "MODEL_LAMBDA_NOOBJ = 0.3\n",
    "\n",
    "THRESHOLD_CONFIDENCE = 0.8 # Threshold for confidence score\n",
    "MODEL_MINIMAL_IOU = 0.4 # Minimal IOU for a box to be considered as a match\n",
    "MODEL_GRID_SENSIBILITY_COEF = 1.2 # Coefficient for the grid expansion\n",
    "MODEL_SIGMOID_MULTIPLIER = 1 # Multiplier for the sigmoid for w,h\n",
    "MODEL_SIGMOID_ADDER = 0.5 # Adder for the sigmoid for w,h\n",
    "\n",
    "MODEL_CELLULES_SIZE = (IMAGE_SIZE[0]/MODEL_CELLULES[0], IMAGE_SIZE[1]/MODEL_CELLULES[1]) # Size of a cell in pixels (height, width)\n",
    "MODEL_ANCHOR_BOXES_PIXELSIZE = [(MODEL_CELLULES_SIZE[0]*anchor[1], MODEL_CELLULES_SIZE[1]*anchor[0]) for anchor in MODEL_ANCHOR_BOXES] # Size of the anchor boxes in pixels\n",
    "MODEL_ANCHOR_BOXES_PIXELSIZE_2 = [(anchor[0]/2,anchor[1]/2) for anchor in MODEL_ANCHOR_BOXES_PIXELSIZE] # Half size of the anchor boxes in pixels\n",
    "MODEL_CELLULES_SIZE_INV = (1/MODEL_CELLULES_SIZE[0], 1/MODEL_CELLULES_SIZE[1]) # Inverse of the size of a cell in pixels (height, width)\n",
    "MODEL_ANCHOR_BOXES_COLOR = [(np.random.rand(),np.random.rand(),np.random.rand()) for i in range(len(MODEL_ANCHOR_BOXES))] # Color for each anchor box\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_filepath = np.array([ (image, label) for image, label in zip(os.listdir(IMAGES_FOLDER), os.listdir(LABELS_FOLDER)) ])\n",
    "dataset_indices = np.arange(len(dataset_filepath))\n",
    "np.random.shuffle(dataset_indices)\n",
    "\n",
    "'''\n",
    "UTILS\n",
    "'''\n",
    "\n",
    "# Select generator\n",
    "def select_generator():\n",
    "    selected_input = input('Choose the generator (train, val, test, default : train) : ')\n",
    "    if selected_input == '' :\n",
    "        return train_generator\n",
    "    elif selected_input == 'train' :\n",
    "        return train_generator\n",
    "    elif selected_input == 'val' :\n",
    "        return val_generator\n",
    "    elif selected_input == 'test' :\n",
    "        return test_generator\n",
    "    else :\n",
    "        raise ValueError('Unknown subset (train, val, test)')\n",
    "\n",
    "# SigmoÃ¯de function\n",
    "def sigmoid(x):\n",
    "    x=np.clip(x, -50, 50)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Softmax function\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Compute IOU\n",
    "def compute_iou(boxA, boxB):\n",
    "    # [x_center, y_center, width, height, confidence]\n",
    "    xA = max(boxA[0] - boxA[2] / 2, boxB[0] - boxB[2] / 2)\n",
    "    yA = max(boxA[1] - boxA[3] / 2, boxB[1] - boxB[3] / 2)\n",
    "    xB = min(boxA[0] + boxA[2] / 2, boxB[0] + boxB[2] / 2)\n",
    "    yB = min(boxA[1] + boxA[3] / 2, boxB[1] + boxB[3] / 2)\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "# Use BoK to calculate the final boxes\n",
    "def calculate_bok(grouped_boxes):\n",
    "    bok_boxes = []\n",
    "\n",
    "    for group in grouped_boxes:\n",
    "        # Extract the coordinates and scores of the boxes in this group\n",
    "        scores = np.array([box[4] for box in group])\n",
    "        boxes = np.array([box[:4] for box in group])\n",
    "\n",
    "        # Use softmax to calculate the weights\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Calculate the weighted box\n",
    "        weighted_box = np.sum(weights[:, None] * boxes, axis=0)  # None is used to add a new axis\n",
    "        bok_boxes.append(weighted_box.tolist()+[np.max(scores)] +[group[np.argmax(scores)][5]]) # Add anchor box index for color\n",
    "\n",
    "    return bok_boxes\n",
    "\n",
    "# Non Maximum Suppression\n",
    "def non_maximum_suppression(boxes):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Extract the coordinates and scores of the boxes\n",
    "    scores = np.array([box[4] for box in boxes])  # Convidence score\n",
    "    boxes_coords = np.array([box[:4] for box in boxes])  # Coordinates\n",
    "\n",
    "    # Sort the boxes by confidence score\n",
    "    indices = np.argsort(-scores)\n",
    "\n",
    "    final_boxes = []\n",
    "    while indices.size > 0:\n",
    "        current_index = indices[0]\n",
    "        current_box = boxes_coords[current_index]\n",
    "        final_boxes.append(boxes[current_index])  # Add the current box to the final list\n",
    "\n",
    "        # Compute the IOU between the current box and all other boxes\n",
    "        mask = np.ones(indices.shape, dtype=bool)\n",
    "        mask[0] = False  # Ignore the current box\n",
    "\n",
    "        # Compute IOU between the current box and all other boxes\n",
    "        for i in range(1, len(indices)):\n",
    "            if compute_iou(current_box, boxes_coords[indices[i]]) > MODEL_MINIMAL_IOU:\n",
    "                mask[i] = False  # Remove the box if the IOU is higher than the threshold\n",
    "\n",
    "        # Update indices for the next iteration\n",
    "        indices = indices[mask]\n",
    "\n",
    "    return final_boxes\n",
    "\n",
    "# Parse prediction of the model ( only 1 image )\n",
    "def parse_prediction(y_pred, bok=BOK_FACTOR):\n",
    "    pred_boxes=y_pred[..., 0:4]\n",
    "    pred_conf=tf.sigmoid(y_pred[..., 4])\n",
    "    boxes = []\n",
    "    # Check each cell\n",
    "    for i in range(MODEL_CELLULES[0]):\n",
    "        for j in range(MODEL_CELLULES[1]):\n",
    "            k_list = np.argsort(pred_conf[i, j])[::-1][:bok]\n",
    "            cell_boxes = []\n",
    "            for k in k_list:\n",
    "                box = pred_boxes[i, j, k]\n",
    "                if pred_conf[i,j,k].numpy() > THRESHOLD_CONFIDENCE :\n",
    "                    # Get the box coordinates\n",
    "                    x_center = (j + MODEL_GRID_SENSIBILITY_COEF*sigmoid(box[0]) - (MODEL_GRID_SENSIBILITY_COEF-1)/2) * MODEL_CELLULES_SIZE[1]\n",
    "                    y_center = (i + MODEL_GRID_SENSIBILITY_COEF*sigmoid(box[1]) - (MODEL_GRID_SENSIBILITY_COEF-1)/2) * MODEL_CELLULES_SIZE[0]\n",
    "                    w_box = (MODEL_SIGMOID_MULTIPLIER*sigmoid(box[2]) + MODEL_SIGMOID_ADDER ) * MODEL_ANCHOR_BOXES[k][0] * MODEL_CELLULES_SIZE[1]\n",
    "                    h_box = (MODEL_SIGMOID_MULTIPLIER*sigmoid(box[3]) + MODEL_SIGMOID_ADDER ) * MODEL_ANCHOR_BOXES[k][1] * MODEL_CELLULES_SIZE[0]\n",
    "                    conf = pred_conf[i,j,k].numpy()\n",
    "                    cell_boxes.append((x_center, y_center, w_box, h_box, conf, k)) \n",
    "            if cell_boxes != []:\n",
    "                boxes.append(cell_boxes)\n",
    "    return boxes\n",
    "\n",
    "# Parse label of the model ( only 1 image )\n",
    "def parse_label(y_true):\n",
    "    boxes = []\n",
    "    for i in range(MODEL_CELLULES[0]):\n",
    "        for j in range(MODEL_CELLULES[1]):\n",
    "            for anchor in range(len(MODEL_ANCHOR_BOXES)):\n",
    "                box = y_true[i, j, anchor]\n",
    "                if box[4] == 1:\n",
    "                    # Get the box coordinates\n",
    "                    x_center_abs = (j + box[0]) * MODEL_CELLULES_SIZE[0]\n",
    "                    y_center_abs = (i + box[1]) * MODEL_CELLULES_SIZE[1]\n",
    "                    width_abs = box[2] * MODEL_ANCHOR_BOXES_PIXELSIZE[anchor][1]\n",
    "                    height_abs = box[3] * MODEL_ANCHOR_BOXES_PIXELSIZE[anchor][0]\n",
    "                    boxes.append((x_center_abs, y_center_abs, width_abs, height_abs, 1, anchor))\n",
    "    return boxes\n",
    "\n",
    "# Calculate IOU metrics\n",
    "def calculate_iou_metrics(predicted_boxes, true_boxes):\n",
    "    ious = []\n",
    "    for pred_box in predicted_boxes:\n",
    "        max_iou = 0 \n",
    "        for true_box in true_boxes:\n",
    "            iou = compute_iou(pred_box, true_box)\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "        ious.append(max_iou)\n",
    "    return ious\n",
    "\n",
    "# Show inference\n",
    "def draw_predict(image, y_pred=None, y_true=None, bok=BOK_FACTOR, title=None):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Add the predicted boxes if available\n",
    "    if y_pred is not None:\n",
    "        # Draw the grid\n",
    "        for i in range(MODEL_CELLULES[1] + 1):  # Lignes verticales\n",
    "            ax.axvline(x=i * MODEL_CELLULES_SIZE[1], color='w', linestyle='-', linewidth=0.1)\n",
    "        for j in range(MODEL_CELLULES[0] + 1):  # Lignes horizontales\n",
    "            ax.axhline(y=j * MODEL_CELLULES_SIZE[0], color='w', linestyle='-', linewidth=0.1)\n",
    "        \n",
    "        # Get the predicted boxes\n",
    "        boxes = parse_prediction(y_pred, bok)\n",
    "        boxes = calculate_bok(boxes)\n",
    "        boxes = non_maximum_suppression(boxes)\n",
    "        # Draw the predicted boxes\n",
    "        for box in boxes:\n",
    "            x_center, y_center, w_box, h_box, conf, k = box\n",
    "            # Calcul des coins de la box\n",
    "            x_min = x_center - w_box / 2\n",
    "            y_min = y_center - h_box / 2\n",
    "            # Dessiner la boÃ®te englobante\n",
    "            rect=patches.Rectangle((x_min, y_min), w_box, h_box, linewidth=1, edgecolor=MODEL_ANCHOR_BOXES_COLOR[k], facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.scatter(x_center, y_center, color=MODEL_ANCHOR_BOXES_COLOR[k], s=2)\n",
    "\n",
    "    # Add the true boxes if available\n",
    "    if y_true is not None :\n",
    "        boxes = parse_label(y_true)\n",
    "        for box in boxes:\n",
    "            x_center_abs, y_center_abs, width_abs, height_abs, _, anchor = box\n",
    "            # Dessiner la boÃ®te englobante\n",
    "            x_min = x_center_abs - width_abs / 2\n",
    "            y_min = y_center_abs - height_abs / 2\n",
    "            rect = patches.Rectangle((x_min, y_min), width_abs, height_abs, linewidth=1, edgecolor=MODEL_ANCHOR_BOXES_COLOR[anchor], facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            # Dessiner un point rouge au centre de la boÃ®te englobante\n",
    "            ax.scatter(x_center_abs, y_center_abs, color=MODEL_ANCHOR_BOXES_COLOR[anchor], s=2)  # `s` contrÃ´le la taille du point\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot metrics\n",
    "def plot_training_curves(history, val_history):\n",
    "    epochs = len(history['loss'])\n",
    "    epoch_range = range(1, epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    metrics = ['loss', 'loss_coord', 'loss_pred_iou', 'loss_pred_noobj', 'best_iou_mean']\n",
    "    titles = ['Loss', 'IOU Loss', 'Conf Loss', 'No Object Loss', 'Best IOU Mean']\n",
    "    y_labels = ['Loss', 'Loss', 'Loss', 'Loss', 'IOU']\n",
    "\n",
    "    for i, metric_key in enumerate(metrics):\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        train_values = [np.mean(loss) for loss in history[metric_key]]\n",
    "        val_values = [np.mean(loss) for loss in val_history['val_' + metric_key]]\n",
    "        plt.plot(epoch_range, train_values, 'b', label='Train Mean', linewidth=2)\n",
    "        plt.plot(epoch_range, val_values, 'r', label='Validation Mean', linewidth=2)\n",
    "        plt.title(titles[i])\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(y_labels[i])\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Select Model learning rate\n",
    "def select_learning_rate():\n",
    "    global MODEL_LEARNING_RATE\n",
    "    learning_rate = input(f'Choose the learning rate (default : {MODEL_LEARNING_RATE}) : ')\n",
    "    if learning_rate != '' :\n",
    "        MODEL_LEARNING_RATE = float(learning_rate)\n",
    "    return MODEL_LEARNING_RATE\n",
    "\n",
    "# Save model with config\n",
    "def save_model_with_config(model):\n",
    "    date_now = datetime.now().strftime(\"%d-%m\")\n",
    "    \n",
    "    # Make the folder\n",
    "    model_folder = f\"{MODEL_FOLDER}/yolo_{date_now}\"\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = f\"{model_folder}/yolo_{date_now}.h5\"\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Save the config\n",
    "    CONSTANTES_LIST = ['MODEL_ANCHOR_BOXES', 'MODEL_CELLULES', 'IMAGE_SIZE', 'MODEL_CELLULES_SIZE', 'THRESHOLD_CONFIDENCE', 'MODEL_MINIMAL_IOU', 'MODEL_GRID_SENSIBILITY_COEF', 'MODEL_SIGMOID_MULTIPLIER', 'MODEL_SIGMOID_ADDER']\n",
    "    config_path = f\"{model_folder}/config.py\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        for constante in CONSTANTES_LIST:\n",
    "            f.write(f\"{constante} = {globals()[constante]}\\n\")\n",
    "    \n",
    "    print(f\"Model saved at {model_path}\")\n",
    "\n",
    "# Stats \n",
    "def print_statistics(data, label):\n",
    "    data = np.array(data)\n",
    "    max_val = np.max(data)\n",
    "    min_val = np.min(data)\n",
    "    mean_val = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    std_dev = np.std(data)\n",
    "    \n",
    "    print(f\"Statistics for {label}:\")\n",
    "    print(f\"  Max: {max_val:.4f}\")\n",
    "    print(f\"  Min: {min_val:.4f}\")\n",
    "    print(f\"  Mean: {mean_val:.4f}\")\n",
    "    print(f\"  Median: {median_val:.4f}\")\n",
    "    print(f\"  Standard Deviation: {std_dev:.4f}\\n\")\n",
    "\n",
    "'''\n",
    "STATS\n",
    "'''\n",
    "print(f'Number of images/labels in the dataset : {len(dataset_indices)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounding boxes from the labels\n",
    "bounding_boxes = []\n",
    "for label,image in zip(os.listdir(LABELS_FOLDER), os.listdir(IMAGES_FOLDER)):\n",
    "    with open(os.path.join(LABELS_FOLDER, label), 'r') as f:\n",
    "        for line in f:\n",
    "            _, _, _, w, h = line.split()\n",
    "            # Get the aspect ratio of the image\n",
    "            with Image.open(os.path.join(IMAGES_FOLDER, image)) as img:\n",
    "                img_w, img_h = img.size\n",
    "            old_aspect_ratio = img_w / img_h\n",
    "            # Get the object \n",
    "            w = float(w) * MODEL_CELLULES[1]\n",
    "            h = float(h) * MODEL_CELLULES[0]\n",
    "            # Add the bounding box to the list\n",
    "            bounding_boxes.append((w, h))\n",
    "\n",
    "kmean_data = np.array(bounding_boxes)\n",
    "print(f'Number of items in the dataset : {kmean_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9 # Number of clusters\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(kmean_data)\n",
    "anchor_boxes = kmeans.cluster_centers_\n",
    "\n",
    "# Plot\n",
    "\n",
    "plt.scatter(kmean_data[:, 0], kmean_data[:, 1], c=kmeans.labels_, cmap='viridis', marker='o', label='Bounding box')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', label='Cluster center')\n",
    "plt.title('Anchor Boxes Clustering')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate inertia and silhouette score\n",
    "inertia = kmeans.inertia_\n",
    "silhouette_avg = silhouette_score(kmean_data, kmeans.labels_)\n",
    "print(f'Model Inertia: {inertia}')\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "anchor_boxes = [ (x,y) for x,y in kmeans.cluster_centers_]\n",
    "print(f'Anchor boxes : {anchor_boxes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class CustomDatasetLoaderYOLO(Sequence):\n",
    "    def __init__(self, subset):\n",
    "        def get_subset(subset, lenght):\n",
    "            train_end = int(DATASET_SPLIT[0] * lenght)\n",
    "            val_end = train_end + int(lenght* DATASET_SPLIT[1])\n",
    "            if subset == 'train':\n",
    "                return 0, train_end\n",
    "            elif subset == 'val':\n",
    "                return train_end,val_end\n",
    "            elif subset == 'test':\n",
    "                return val_end, lenght\n",
    "            else:\n",
    "                raise ValueError('Unknown subset (train, val, test)')\n",
    "        \n",
    "        start, stop = get_subset(subset, len(dataset_indices))\n",
    "        self.indices = dataset_indices[start:stop]\n",
    " \n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.indices) / MODEL_BATCH_SIZE).astype('int')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * MODEL_BATCH_SIZE : (idx + 1) * MODEL_BATCH_SIZE]\n",
    "\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for image, label in dataset_filepath[batch_indices] :\n",
    "            # load image\n",
    "            with Image.open(os.path.join(IMAGES_FOLDER,image)) as img:\n",
    "                img = img.convert('RGB')\n",
    "                #original_image_height, original_image_width = img.size\n",
    "                #ratiox = original_image_height / IMAGE_SIZE[0]\n",
    "                #ratioy = original_image_width / IMAGE_SIZE[1]\n",
    "                img = img.resize((IMAGE_SIZE[1],IMAGE_SIZE[0]))\n",
    "                batch_images.append(np.array(img))\n",
    "            # load label\n",
    "            img_label = np.zeros((MODEL_CELLULES[0], MODEL_CELLULES[1], len(MODEL_ANCHOR_BOXES) ,5), dtype=np.float32)\n",
    "            for line in open(os.path.join(LABELS_FOLDER,label)).readlines():\n",
    "                _ ,x_center, y_center, width, height = line.split()[0:5] # we use _ because we don't use the class index\n",
    "                x_center, y_center, width, height = map(float, (x_center, y_center, width, height))\n",
    "                \n",
    "                \n",
    "                # Find the right cell\n",
    "                cell_x, rest_x = divmod(MODEL_CELLULES[1]*x_center, 1) # Y is height et X is width\n",
    "                cell_y, rest_y = divmod(MODEL_CELLULES[0]*y_center, 1)\n",
    "\n",
    "                # Find ther cell size\n",
    "                box_width, box_height = width * IMAGE_SIZE[1], height * IMAGE_SIZE[0]\n",
    "\n",
    "                # Find the right anchor box = the one with the best IOU\n",
    "                best_iou = 0\n",
    "                for i, (anchorbox_height, anchorbox_width) in enumerate(MODEL_ANCHOR_BOXES_PIXELSIZE):\n",
    "                    iou = min(anchorbox_width, box_width) * min(anchorbox_height, box_height) / (max(anchorbox_width, box_width) * max(anchorbox_height, box_height))\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_anchor = i\n",
    "                # Calculate the coords inside the cell\n",
    "                width_cell = box_width / (MODEL_ANCHOR_BOXES[best_anchor][0]*MODEL_CELLULES_SIZE[0])\n",
    "                height_cell = box_height / (MODEL_ANCHOR_BOXES[best_anchor][1]*MODEL_CELLULES_SIZE[1])\n",
    "\n",
    "                # Adding coords to the label\n",
    "                img_label[int(cell_y), int(cell_x), best_anchor, 0] = rest_x\n",
    "                img_label[int(cell_y), int(cell_x), best_anchor, 1] = rest_y\n",
    "                img_label[int(cell_y), int(cell_x), best_anchor, 2] = width_cell\n",
    "                img_label[int(cell_y), int(cell_x), best_anchor, 3] = height_cell\n",
    "                img_label[int(cell_y), int(cell_x), best_anchor, 4] = 1 # Show that there is an item at this cell and anchor\n",
    "            batch_labels.append(img_label)\n",
    "\n",
    "        batch_images = np.asarray(batch_images)/ 255\n",
    "        batch_labels = np.asarray(batch_labels).astype(np.float32)\n",
    "        \n",
    "        return batch_images ,batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "train_generator = CustomDatasetLoaderYOLO('train')\n",
    "val_generator = CustomDatasetLoaderYOLO('val')\n",
    "test_generator = CustomDatasetLoaderYOLO('test')\n",
    "\n",
    "print(f'train dataset lenght : {len(train_generator)}')\n",
    "print(f'Number of images in train dataset : {len(train_generator.indices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show random image+label from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_image_with_boxes_and_grid(generator, figsize=(12, 12)):\n",
    "    # Extract data from generator\n",
    "    generator_len = len(generator)\n",
    "    random_id = np.random.randint(0, generator_len)\n",
    "    images, labels = generator[random_id]\n",
    "    idx = np.random.choice(images.shape[0])\n",
    "    image = images[idx]\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    # Show image\n",
    "    ax.imshow(image)\n",
    "\n",
    "\n",
    "    # Plot cells\n",
    "    for i in range(MODEL_CELLULES[1] + 1):  # Lignes verticales\n",
    "        ax.axvline(x=i * MODEL_CELLULES_SIZE[1], color='w', linestyle='-', linewidth=0.1)\n",
    "    for j in range(MODEL_CELLULES[0] + 1):  # Lignes horizontales\n",
    "        ax.axhline(y=j * MODEL_CELLULES_SIZE[0], color='w', linestyle='-', linewidth=0.1)\n",
    "\n",
    "    # Plot bounding boxes\n",
    "    label = labels[idx]\n",
    "    for i in range(MODEL_CELLULES[0]): \n",
    "        for j in range(MODEL_CELLULES[1]):\n",
    "            for anchor in range(len(MODEL_ANCHOR_BOXES_PIXELSIZE)):\n",
    "                box = label[i, j, anchor]\n",
    "                if box[4] == 1:  # Detect item\n",
    "                    # Absolute coords of the bounding box\n",
    "                    x_center_abs = (j + box[0]) * MODEL_CELLULES_SIZE[0]\n",
    "                    y_center_abs = (i + box[1]) * MODEL_CELLULES_SIZE[1]\n",
    "                    width_abs = box[2] * MODEL_ANCHOR_BOXES_PIXELSIZE[anchor][1]\n",
    "                    height_abs = box[3] * MODEL_ANCHOR_BOXES_PIXELSIZE[anchor][0]\n",
    "\n",
    "                    # Plot of the bounding box\n",
    "                    x_min = x_center_abs - width_abs / 2\n",
    "                    y_min = y_center_abs - height_abs / 2\n",
    "                    rect = patches.Rectangle((x_min, y_min), width_abs, height_abs, linewidth=1, edgecolor=MODEL_ANCHOR_BOXES_COLOR[anchor], facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.scatter(x_center_abs, y_center_abs, color='r', s=1)  # add little dot\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_sample_image_with_boxes_and_grid(select_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure processing time\n",
    "\n",
    "----\n",
    "**Avg computer**\n",
    "\n",
    "Mean batch time for train set: 85.7 ms +- 41.9 ms\n",
    "\n",
    "Mean batch time for val set: 86.0 ms +- 45.7 ms\n",
    "\n",
    "Mean batch time for test set: 86.7 ms +- 32.8 ms\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_generator_speed(generator):\n",
    "    times = []\n",
    "    \n",
    "    for i in range(len(generator)) :\n",
    "        start_time = time.time()\n",
    "        generator[i]\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        times.append(total_time)\n",
    "    \n",
    "    avg_time = np.mean(times) * 1000\n",
    "    std_time = np.std(times) * 1000\n",
    "    \n",
    "    \n",
    "    return avg_time, std_time\n",
    "\n",
    "# Measure the speed of the generators\n",
    "avg_time_train, std_time_train = measure_generator_speed(train_generator)\n",
    "avg_time_val, std_time_val = measure_generator_speed(val_generator)\n",
    "avg_time_test, std_time_test = measure_generator_speed(test_generator)\n",
    "\n",
    "print(f\"Mean batch time for train set: {avg_time_train:.1f} ms +- {std_time_train:.1f} ms\")\n",
    "print(f\"Mean batch time for val set: {avg_time_val:.1f} ms +- {std_time_val:.1f} ms\")\n",
    "print(f\"Mean batch time for test set: {avg_time_test:.1f} ms +- {std_time_test:.1f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLO():\n",
    "    def res_block(input, filters, size=2, kernel_size=3, dropout=0.05) :\n",
    "        skip = input\n",
    "        for i in range(size) :\n",
    "            input = layers.Conv2D(filters, kernel_size, padding='same')(input)\n",
    "            input = layers.BatchNormalization()(input)\n",
    "            input = layers.LeakyReLU(alpha=0.1)(input)\n",
    "            input = layers.Dropout(dropout)(input)\n",
    "        input = layers.Add()([skip, input])\n",
    "        input = layers.BatchNormalization()(input)\n",
    "        input = layers.LeakyReLU(alpha=0.1)(input)\n",
    "        return input\n",
    "\n",
    "    # Input\n",
    "    input_img = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "    x = layers.BatchNormalization()(input_img)\n",
    "    x = layers.Dropout(0.10)(x)\n",
    "    x = layers.Conv2D(16, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(4) :\n",
    "        x = res_block(x, 16, 3)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(4) :\n",
    "        x = res_block(x, 32, 3)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(4) :\n",
    "        x = res_block(x, 64, 3)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(4) :\n",
    "        x = res_block(x, 128, 3)\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(4) :\n",
    "        x = res_block(x, 256, 3)\n",
    "    x = layers.Conv2D(512, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    for i in range(5) :\n",
    "        x = res_block(x, 512, 3)\n",
    "\n",
    "    # Output\n",
    "    output = layers.Conv2D(5*len(MODEL_ANCHOR_BOXES), (3, 3), padding='same')(x)\n",
    "    output = layers.Reshape((MODEL_CELLULES[0], MODEL_CELLULES[1], len(MODEL_ANCHOR_BOXES), 5))(output)\n",
    "\n",
    "    # Model\n",
    "    model = models.Model(inputs=input_img, outputs=output, name='MiniYOLO')\n",
    "    return model\n",
    "\n",
    "model = YOLO()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = []\n",
    "for root, dirs, files in os.walk(MODEL_FOLDER):\n",
    "    for file in files:\n",
    "        if file.endswith('.h5'):\n",
    "            model_files.append(os.path.join(root, file))\n",
    "\n",
    "# Dropdown widget to select the model\n",
    "dropdown = Dropdown(\n",
    "    options=model_files,\n",
    "    description='Select Model:',\n",
    "    layout=Layout(width='50%', height='30px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def button_load_model(b):\n",
    "    global model\n",
    "    model_path = dropdown.value\n",
    "    model = load_model(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    load_button.close()\n",
    "    dropdown.close()\n",
    "\n",
    "# Button to load the model\n",
    "load_button = Button(description=\"Load Model\")\n",
    "load_button.on_click(button_load_model)\n",
    "\n",
    "# Plot the widget\n",
    "display(VBox([dropdown, load_button]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIOU / PRED_IOU (loss_coord, loss_conf_iou, loss_noobj)\n",
    "@tf.function\n",
    "def yolo_loss(y_true, y_pred):\n",
    "  \n",
    "    # Loss functions\n",
    "    binary_crossentropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    binary_crossentropy_ls = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE, label_smoothing=0.01)\n",
    "\n",
    "    # Constants\n",
    "    anchor_sizes = tf.constant(MODEL_ANCHOR_BOXES, dtype=tf.float32)\n",
    "    pattern_ascending = tf.tile(tf.range(MODEL_CELLULES[1], dtype=tf.float32)[tf.newaxis, :], [MODEL_CELLULES[0], 1]) # Pour les coordonnÃ©es x (0,1,2,..,MODEL_CELLULES[1]-1)\n",
    "    pattern_row_index = tf.tile(tf.range(MODEL_CELLULES[0], dtype=tf.float32)[:, tf.newaxis], [1, MODEL_CELLULES[1]]) # Pour les coordonnÃ©es y (0,0,0,..,MODEL_CELLULES[0]-1)\n",
    "    pattern_ascending = tf.expand_dims(pattern_ascending, axis=0)  # Ajouter des dimensions pour la compatibilitÃ© avec les calculs\n",
    "    pattern_ascending = tf.expand_dims(pattern_ascending, axis=-1)  # Ajouter des dimensions pour la compatibilitÃ© avec les calculs\n",
    "    pattern_row_index = tf.expand_dims(pattern_row_index, axis=0)  # Ajouter des dimensions pour la compatibilitÃ© avec les calculs\n",
    "    pattern_row_index = tf.expand_dims(pattern_row_index, axis=-1)  # Ajouter des dimensions pour la compatibilitÃ© avec les calculs\n",
    "\n",
    "    # Splitting the prediction\n",
    "    pred_x, pred_y, pred_w, pred_h, pred_conf= tf.split(y_pred, (1, 1, 1, 1, 1), axis=-1)\n",
    "    pred_x = tf.squeeze(pred_x, axis=-1)\n",
    "    pred_y = tf.squeeze(pred_y, axis=-1)\n",
    "    pred_w = tf.squeeze(pred_w, axis=-1)\n",
    "    pred_h = tf.squeeze(pred_h, axis=-1)\n",
    "    pred_conf = tf.squeeze(pred_conf, axis=-1)\n",
    "    converted_pred_x = pattern_ascending + MODEL_GRID_SENSIBILITY_COEF*tf.sigmoid(pred_x) - (MODEL_GRID_SENSIBILITY_COEF-1)/2\n",
    "    converted_pred_y = pattern_row_index + MODEL_GRID_SENSIBILITY_COEF*tf.sigmoid(pred_y) - (MODEL_GRID_SENSIBILITY_COEF-1)/2\n",
    "    converted_pred_w = (MODEL_SIGMOID_MULTIPLIER*tf.sigmoid(pred_w) + MODEL_SIGMOID_ADDER )* anchor_sizes[:, 0]\n",
    "    converted_pred_h = (MODEL_SIGMOID_MULTIPLIER*tf.sigmoid(pred_h) + MODEL_SIGMOID_ADDER )* anchor_sizes[:, 1]\n",
    "    converted_pred_conf = tf.sigmoid(pred_conf)\n",
    "    \n",
    "    # Splitting the true values\n",
    "    true_x, true_y, true_w, true_h, true_conf = tf.split(y_true, (1, 1, 1, 1, 1), axis=-1)\n",
    "    true_x = tf.math.reduce_sum(tf.squeeze(true_x, axis=-1), axis=-1, keepdims=True)\n",
    "    true_y = tf.math.reduce_sum(tf.squeeze(true_y, axis=-1), axis=-1, keepdims=True)\n",
    "    converted_true_x = true_x + pattern_ascending\n",
    "    converted_true_y = true_y + pattern_row_index\n",
    "    true_w = tf.squeeze(true_w, axis=-1)\n",
    "    true_h = tf.squeeze(true_h, axis=-1)\n",
    "    converted_true_w = tf.math.reduce_sum(true_w * anchor_sizes[:, 0], axis=-1, keepdims=True)  # Largeur vraie ajustÃ©e\n",
    "    converted_true_h = tf.math.reduce_sum(true_h * anchor_sizes[:, 1], axis=-1, keepdims=True)  # Hauteur vraie ajustÃ©e\n",
    "    true_conf = tf.squeeze(true_conf, axis=-1)\n",
    "\n",
    "    # Masking\n",
    "    obj = tf.cast(true_conf == 1, tf.float32)\n",
    "    obj_area = tf.reduce_sum(obj, axis=-1, keepdims=True)\n",
    "    noobj_area = tf.reduce_sum(1-obj, axis=-1, keepdims=True)\n",
    "    noobj = tf.cast(true_conf == 0, tf.float32)\n",
    "    nb_obj = tf.reduce_sum(obj)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     Calculates GIOU and DIOU between predicted anchor boxes and ground truths,\n",
    "    taking into account different anchor box sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the predicted values to absolute coordinates\n",
    "    true_x_min, true_y_min = converted_true_x - converted_true_w / 2, converted_true_y - converted_true_h / 2\n",
    "    true_x_max, true_y_max = converted_true_x + converted_true_w / 2, converted_true_y + converted_true_h / 2\n",
    "        \n",
    "    pred_x_min, pred_y_min = converted_pred_x - converted_pred_w / 2, converted_pred_y - converted_pred_h / 2\n",
    "    pred_x_max, pred_y_max = converted_pred_x + converted_pred_w / 2, converted_pred_y + converted_pred_h / 2\n",
    "        \n",
    "    # Intersection coordinates\n",
    "    inter_x_min = tf.maximum(true_x_min, pred_x_min)\n",
    "    inter_y_min = tf.maximum(true_y_min, pred_y_min)\n",
    "    inter_x_max = tf.minimum(true_x_max, pred_x_max)\n",
    "    inter_y_max = tf.minimum(true_y_max, pred_y_max)\n",
    "        \n",
    "    # Enclosing box coordinates\n",
    "    englob_x_min = tf.minimum(true_x_min, pred_x_min)\n",
    "    englob_y_min = tf.minimum(true_y_min, pred_y_min)\n",
    "    englob_x_max = tf.maximum(true_x_max, pred_x_max)\n",
    "    englob_y_max = tf.maximum(true_y_max, pred_y_max)\n",
    "        \n",
    "    # Intersection area\n",
    "    inter_area = tf.maximum(inter_x_max - inter_x_min, 0) * tf.maximum(inter_y_max - inter_y_min, 0)\n",
    "    # True and predicted areas\n",
    "    true_area = (true_x_max - true_x_min) * (true_y_max - true_y_min)\n",
    "    pred_area = (pred_x_max - pred_x_min) * (pred_y_max - pred_y_min)\n",
    "    # Union area\n",
    "    union_area = true_area + pred_area - inter_area\n",
    "    # Center distance\n",
    "    center_distance = tf.square(converted_true_x - converted_pred_x) + tf.square(converted_true_y - converted_pred_y)\n",
    "    # Calculate the \"smallest enclosing box covering the two boxes diagonal line squared\"\n",
    "    max_distance = tf.square( englob_x_max - englob_x_min) + tf.square(englob_y_max - englob_y_min)\n",
    "    max_box_area = (englob_x_max - englob_x_min) * (englob_y_max - englob_y_min)\n",
    "    # IOU\n",
    "    iou = inter_area / (union_area + 1e-6) # CAREFUL WITH DIVISION BY ZERO\n",
    "    # DIoU\n",
    "    distance_factor = center_distance / (max_distance + 1e-6) # CAREFUL WITH DIVISION BY ZERO\n",
    "    diou = iou - distance_factor\n",
    "    diouloss = (1 - diou) * obj_area\n",
    "    # GIoU\n",
    "    giou = iou - (max_box_area - true_area - pred_area + union_area) / (max_box_area + 1e-6)\n",
    "    giouloss = (1 - giou) * obj_area\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Loss calculation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loss from the coordinates\n",
    "    loss_coord = tf.reduce_sum(giouloss)\n",
    "    loss_coord = MODEL_LAMBDA_COORD * loss_coord / (nb_obj*len(MODEL_ANCHOR_BOXES)+1e-6)\n",
    "\n",
    "    # loss from the confidence for cells with objects (we want the model to learn to predict its IOU)\n",
    "    loss_pred_iou = MODEL_LAMBDA_IOU * tf.reduce_sum(binary_crossentropy(converted_pred_conf*obj_area, iou)) / (nb_obj+1e-6)\n",
    "\n",
    "    # Loss from the confidence for cells without objects\n",
    "    loss_pred_noobj = MODEL_LAMBDA_NOOBJ * tf.reduce_sum(binary_crossentropy_ls(converted_pred_conf*noobj_area, true_conf*noobj_area)) / (MODEL_BATCH_SIZE * (MODEL_CELLULES[0] * MODEL_CELLULES[1] * len(MODEL_ANCHOR_BOXES)) - nb_obj+1e-6)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = loss_coord + loss_pred_iou + loss_pred_noobj\n",
    "    \n",
    "    # Useful metrics\n",
    "    best_iou_mean = tf.reduce_sum(tf.reduce_max(iou, axis=-1)) / (nb_obj+1e-6)\n",
    "    \n",
    "    return total_loss, (loss_coord, loss_pred_iou, loss_pred_noobj, best_iou_mean)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=select_learning_rate())\n",
    "print(f'Learning rate : {optimizer.learning_rate.numpy()}')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss, loss_data = yolo_loss(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, loss_data\n",
    "\n",
    "# Training loop\n",
    "best_loss_epoch = 0\n",
    "best_loss = float('inf')\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'loss_coord' : [],\n",
    "    'loss_pred_iou' : [],\n",
    "    'loss_pred_noobj' : [],\n",
    "    'best_iou_mean' : [],\n",
    "}\n",
    "val_history = {\n",
    "    'val_loss' : [],\n",
    "    'val_loss_coord' : [],\n",
    "    'val_loss_pred_iou' : [],\n",
    "    'val_loss_pred_noobj' : [],\n",
    "    'val_best_iou_mean' : [],\n",
    "}\n",
    "for epoch in range(MODEL_EPOCHS):\n",
    "    found_better_loss = False\n",
    "    # Train loop\n",
    "    with tqdm(total=len(train_generator), desc=f'Training {epoch+1}/{MODEL_EPOCHS}', unit='batch') as pbar:\n",
    "        epoch_losses = {\n",
    "            'loss' : [],\n",
    "            'loss_coord' : [],\n",
    "            'loss_pred_iou' : [],\n",
    "            'loss_pred_noobj' : [],\n",
    "            'best_iou_mean' : [],\n",
    "        }\n",
    "        for step in range(len(train_generator)) :\n",
    "            inputs, labels = train_generator[step]\n",
    "            # Batch training\n",
    "            loss, loss_data = train_step(inputs, labels)\n",
    "            loss_coord, loss_pred_iou, loss_pred_noobj, best_iou_mean = loss_data\n",
    "            # Metrics\n",
    "            epoch_losses['loss'].append(loss.numpy())\n",
    "            epoch_losses['loss_coord'].append(loss_coord.numpy())\n",
    "            epoch_losses['loss_pred_iou'].append(loss_pred_iou.numpy())\n",
    "            epoch_losses['loss_pred_noobj'].append(loss_pred_noobj.numpy())\n",
    "            epoch_losses['best_iou_mean'].append(best_iou_mean.numpy())\n",
    "\n",
    "            mean_epoch_loss = np.mean(epoch_losses['loss'])\n",
    "            mean_epoch_loss_coord = np.mean(epoch_losses['loss_coord'])\n",
    "            mean_epoch_loss_pred_iou = np.mean(epoch_losses['loss_pred_iou'])\n",
    "            mean_epoch_loss_pred_noobj = np.mean(epoch_losses['loss_pred_noobj'])\n",
    "            mean_epoch_best_iou_mean = np.mean(epoch_losses['best_iou_mean'])\n",
    "            pbar.set_postfix({'Loss' :f\"{mean_epoch_loss:.6f}\",\n",
    "                              'Loss coord' :f\"{mean_epoch_loss_coord:.6f}\",\n",
    "                              'Loss pred iou' :f\"{mean_epoch_loss_pred_iou:.6f}\",\n",
    "                              'Loss noobj' :f\"{mean_epoch_loss_pred_noobj:.6f}\",\n",
    "                              'Best IOU Mean' :f\"{mean_epoch_best_iou_mean:.3f}\",\n",
    "            }\n",
    "            )\n",
    "            \n",
    "            pbar.update()\n",
    "    train_generator.on_epoch_end()\n",
    "    history['loss'].append(epoch_losses['loss'])\n",
    "    history['loss_coord'].append(epoch_losses['loss_coord'])\n",
    "    history['loss_pred_iou'].append(epoch_losses['loss_pred_iou'])\n",
    "    history['loss_pred_noobj'].append(epoch_losses['loss_pred_noobj'])\n",
    "    history['best_iou_mean'].append(epoch_losses['best_iou_mean'])\n",
    "\n",
    "    # Val loop\n",
    "    with tqdm(total=len(val_generator), desc=f'Validation {epoch+1}/{MODEL_EPOCHS}', unit='batch') as pbar:\n",
    "        val_epoch_losses = {\n",
    "            'val_loss' : [],\n",
    "            'val_loss_coord' : [],\n",
    "            'val_loss_pred_iou' : [],\n",
    "            'val_loss_pred_noobj' : [],\n",
    "            'val_best_iou_mean' : [],\n",
    "        }\n",
    "        for step in range(len(val_generator)) :\n",
    "            inputs, labels = val_generator[step]\n",
    "            # Batch inference\n",
    "            predictions = model(inputs, training=False) # No dropout\n",
    "            loss, loss_data = yolo_loss(labels, predictions)\n",
    "            loss_coord, loss_pred_iou, loss_pred_noobj, best_iou_mean = loss_data\n",
    "            # Metrics\n",
    "            val_epoch_losses['val_loss'].append(loss.numpy())\n",
    "            val_epoch_losses['val_loss_coord'].append(loss_coord.numpy())\n",
    "            val_epoch_losses['val_loss_pred_iou'].append(loss_pred_iou.numpy())\n",
    "            val_epoch_losses['val_loss_pred_noobj'].append(loss_pred_noobj.numpy())\n",
    "            val_epoch_losses['val_best_iou_mean'].append(best_iou_mean.numpy())\n",
    "\n",
    "            mean_val_epoch_loss = np.mean(val_epoch_losses['val_loss'])\n",
    "            mean_val_epoch_loss_coord = np.mean(val_epoch_losses['val_loss_coord'])\n",
    "            mean_val_epoch_loss_pred_iou = np.mean(val_epoch_losses['val_loss_pred_iou'])\n",
    "            mean_val_epoch_loss_pred_noobj = np.mean(val_epoch_losses['val_loss_pred_noobj'])\n",
    "            mean_val_epoch_best_iou_mean = np.mean(val_epoch_losses['val_best_iou_mean'])\n",
    "\n",
    "            pbar.set_postfix({'Loss' :f\"{mean_val_epoch_loss:.6f}\",\n",
    "                              'Loss coord' :f\"{mean_val_epoch_loss_coord:.6f}\",\n",
    "                              'Loss pred iou' :f\"{mean_val_epoch_loss_pred_iou:.6f}\",\n",
    "                              'Loss noobj' :f\"{mean_val_epoch_loss_pred_noobj:.6f}\",\n",
    "                              'Best IOU Mean' :f\"{mean_val_epoch_best_iou_mean:.3f}\",\n",
    "            }\n",
    "            )\n",
    "        \n",
    "            pbar.update()\n",
    "    val_epoch_loss = np.mean(val_epoch_losses['val_loss'])\n",
    "    val_history['val_loss'].append(val_epoch_losses['val_loss'])\n",
    "    val_history['val_loss_coord'].append(val_epoch_losses['val_loss_coord'])\n",
    "    val_history['val_loss_pred_iou'].append(val_epoch_losses['val_loss_pred_iou'])\n",
    "    val_history['val_loss_pred_noobj'].append(val_epoch_losses['val_loss_pred_noobj'])\n",
    "    val_history['val_best_iou_mean'].append(val_epoch_losses['val_best_iou_mean'])\n",
    "    \n",
    "    # Compare epoch with the best epoch yet\n",
    "    if val_epoch_loss < best_loss :\n",
    "        best_loss_epoch = epoch\n",
    "        best_loss = val_epoch_loss\n",
    "        found_better_loss = True\n",
    "        print(f'Found a better validation epoch with a mean loss of {best_loss:.6f}')\n",
    "\n",
    "    # Plot and save model\n",
    "    if found_better_loss:\n",
    "        random_id = np.random.randint(0, len(val_generator))\n",
    "        selected_images, selected_labels = val_generator[random_id]\n",
    "        random_idx = np.random.randint(0, selected_images.shape[0])\n",
    "        selected_image = np.expand_dims(selected_images[random_idx], axis=0)\n",
    "        selected_label = selected_labels[random_idx]\n",
    "        # Inference\n",
    "        predictions = model(selected_image, training=True)[0]\n",
    "        draw_predict(selected_image[0], y_pred=predictions, bok=3)\n",
    "        # Save model\n",
    "        save_model_with_config(model)\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch - best_loss_epoch >= MODEL_PATIENCE:\n",
    "        print(f\"Training stopped. No improvement was seen in the last {MODEL_PATIENCE} epochs.\")\n",
    "        break\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history, val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on an random image from a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from generator\n",
    "generator = select_generator()\n",
    "generator_len = len(generator)\n",
    "random_id = np.random.randint(0, generator_len)\n",
    "images, labels = generator[random_id]\n",
    "idx = np.random.choice(images.shape[0])\n",
    "image = images[idx]\n",
    "label = labels[idx]\n",
    "image = np.expand_dims(image, axis=0)\n",
    "label = np.expand_dims(label, axis=0)\n",
    "y_pred = model(image,training=False)\n",
    "\n",
    "draw_predict(image[0], y_pred[0], bok=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison for BoK factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5, 6, 7]\n",
    "generator = select_generator()\n",
    "ious = []\n",
    "for number in numbers:\n",
    "    ious_number = []\n",
    "    with tqdm(total=len(generator), desc=f'BoK {number}', unit='batch') as pbar:\n",
    "        for step in range(len(generator)) :\n",
    "            inputs, labels = generator[step]\n",
    "            predictions = model(inputs, training=False)\n",
    "            for i in range(len(inputs)):\n",
    "                label = labels[i]\n",
    "                prediction = predictions[i]\n",
    "\n",
    "                parsed_labels = parse_label(label)\n",
    "                parsed_predictions = parse_prediction(prediction, bok=number)\n",
    "                final_boxes = non_maximum_suppression(calculate_bok(parsed_predictions))\n",
    "\n",
    "                input_iou = calculate_iou_metrics(parsed_labels, final_boxes)\n",
    "            ious_number += input_iou\n",
    "            pbar.update()\n",
    "    ious.append(ious_number)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "positions = range(1, len(numbers) + 1)\n",
    "box = ax.boxplot(ious, positions=positions, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
    "\n",
    "# Add statistics as text on the graph\n",
    "stats = {\n",
    "    'mean': [],\n",
    "    'std': [],\n",
    "    'median': []\n",
    "}\n",
    "\n",
    "for ious_number in ious:\n",
    "    stats['mean'].append(np.mean(ious_number))\n",
    "    stats['std'].append(np.std(ious_number))\n",
    "    stats['median'].append(np.median(ious_number))\n",
    "\n",
    "y_offset = 0.01 \n",
    "text_color = 'black'\n",
    "for pos, mean, std, median in zip(positions, stats['mean'], stats['std'], stats['median']):\n",
    "    ax.text(pos, median - y_offset, f'Median: {median:.2f}', horizontalalignment='center', color=text_color, weight='bold', verticalalignment='top')\n",
    "    ax.text(pos, mean - 2*y_offset, f'Mean: {mean:.2f}\\nSTD: {std:.2f}', horizontalalignment='center', color=text_color, verticalalignment='top')\n",
    "\n",
    "# Change the labels for the BoK configurations\n",
    "labels = [f'BoK {num}' for num in numbers]\n",
    "labels[0] = 'BoK 1 = NMS'\n",
    "\n",
    "plt.xticks(ticks=positions, labels=labels)\n",
    "plt.xlabel('Configuration BoK')\n",
    "plt.ylabel('IOU Score')\n",
    "plt.title('Boxplot of IOU Scores for Different BoK Configurations')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test on a specific image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"datasets/yolo/images/2505_inventory26.png\"\n",
    "with Image.open(image_path) as img:\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((IMAGE_SIZE[1],IMAGE_SIZE[0]))\n",
    "    img = np.array(img)/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "y_pred = model(img,training=False)\n",
    "draw_predict(img[0], y_pred[0], bok=BOK_FACTOR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and display it\n",
    "def load_image(b):\n",
    "    image_path = image_dropdown.value\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "        output_image.clear_output()\n",
    "        with output_image:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        global img_array  # Use it later for prediction\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Predict and display the bounding boxes\n",
    "def predict(b):\n",
    "    if 'img_array' in globals():\n",
    "        y_pred = model(img_array, training=False)\n",
    "        output_prediction.clear_output()\n",
    "        with output_prediction:\n",
    "            draw_predict(img_array[0], y_pred[0], bok=BOK_FACTOR)\n",
    "\n",
    "# Widgets\n",
    "image_files = [os.path.join(IMAGES_FOLDER, file) for file in os.listdir(IMAGES_FOLDER) if file.endswith('.jpg') or file.endswith('.png')]\n",
    "image_dropdown = Dropdown(options=image_files, description='Select Image:')\n",
    "\n",
    "button_load = Button(description='Load Image')\n",
    "button_predict = Button(description='Predict')\n",
    "\n",
    "output_image = Output()\n",
    "output_prediction = Output()\n",
    "\n",
    "button_load.on_click(load_image)\n",
    "button_predict.on_click(predict)\n",
    "\n",
    "# Layout\n",
    "box_layout = Layout()\n",
    "button_box = HBox([button_load, button_predict], layout=box_layout)\n",
    "output_box = HBox([output_image, output_prediction], layout=box_layout)\n",
    "\n",
    "# Display\n",
    "display(image_dropdown, button_box, output_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison BoK vs NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = select_generator()\n",
    "\n",
    "ious_nms = []\n",
    "ious_bok = []\n",
    "with tqdm(total=len(generator), desc='Processing Batches', unit='batch') as pbar:\n",
    "    for step in range(len(generator)):\n",
    "        inputs, labels = generator[step]\n",
    "\n",
    "        predictions = model(inputs, training=False)\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            label = labels[i]\n",
    "            prediction = predictions[i]\n",
    "\n",
    "            parsed_labels = parse_label(label)  # [[x_center, y_center, width, height, 1, anchor_index], ..]\n",
    "            predicted_boxes_bok = parse_prediction(prediction, bok=BOK_FACTOR)  # [[(x_center, y_center, width, height, confidence, anchor_index)], ..]\n",
    "            predicted_boxes_nms = [tuple(box[0]) for box in predicted_boxes_bok]  # [(x_center, y_center, width, height, confidence, anchor_index), ..] Keep only the best box\n",
    "            \n",
    "\n",
    "            # Calculate the final boxes\n",
    "            final_boxes_nms = non_maximum_suppression(predicted_boxes_nms)\n",
    "            final_boxes_bok = non_maximum_suppression(calculate_bok(predicted_boxes_bok))\n",
    "\n",
    "            # Calculate IOU metrics\n",
    "            iou_nms = calculate_iou_metrics(final_boxes_nms, parsed_labels)\n",
    "            iou_bok = calculate_iou_metrics(final_boxes_bok, parsed_labels)\n",
    "\n",
    "        ious_nms += iou_nms\n",
    "        ious_bok += iou_bok\n",
    "        pbar.update(1)\n",
    "\n",
    "# Plot the IOU distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(ious_nms, bins=500, alpha=0.7, label='NMS IOU', color='blue')\n",
    "plt.hist(ious_bok, bins=500, alpha=0.7, label='BoK IOU', color='green')\n",
    "plt.xlabel('IOU Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of IOU Scores for NMS vs. BoK')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print_statistics(ious_nms, 'NMS IOU')\n",
    "print_statistics(ious_bok, 'BoK IOU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
